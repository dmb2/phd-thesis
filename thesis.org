#+TITLE:     A Measurement of the Radiation Environment Around Prompt J/\psi Events at ATLAS
#+AUTHOR:    David Bjergaard
#+OPTIONS:   H:3 num:t toc:nil ':t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:nil
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc

#+LATEX_CLASS: dukedissertation
#+LATEX_HEADER:\supervisor{Ayana T Arce}
#+LATEX_HEADER:\department{Physics}
#+DATE: 2017
#+LATEX_HEADER:\member{Tom C. Mehen}
#+LATEX_HEADER:\member{Mark C. Kruse}
#+LATEX_HEADER:\member{Ashutosh V. Kotwal}
#+LATEX_HEADER:\member{Glenn Edwards}
#+LATEX_HEADER:\addbibresource{thesis.bib}

#+LATEX_HEADER:\input{acronyms.tex}

#+LATEX_HEADER:\hypersetup{
#+LATEX_HEADER:plainpages=false,
#+LATEX_HEADER:bookmarksnumbered,
#+LATEX_HEADER:colorlinks, linkcolor=black, citecolor=black,
#+LATEX_HEADER:filecolor=black, urlcolor=black,
#+LATEX_HEADER:}


#+INCLUDE: abstract.org
# ``Life is short,\\ 
# and art long,\\
# opportunity fleeting,\\
# experimentations perilous,\\
# and judgement difficult''\\
# -- Hippocrates \emph{Aphorismi}


#+BEGIN_LaTeX
\addcontentsline{toc}{chapter}{Dedication} 
\chapter*{Dedication}
\begin{flushright}
\emph{To my wife.}
\end{flushright}
#+END_LaTeX
#+BEGIN_LaTeX
\tableofcontents
\listoftables
\listoffigures
% \printglossary[type=\acronymtype]
% \addcontentsline{toc}{chapter}{Acronyms} 
#+END_LaTeX

#+INCLUDE: acknowledgements.org

#+LaTeX: \chapter{Introduction}
* A brief history
The history of particle physics spans over a century of experimental
and theoretical development that has lead to some of the deepest
insights into nature. The starting point for this work began during
the post-war period of the early 1950s. A series of bubble chamber
experiments led to the discovery of the $\Lambda$, $\Xi$ and $\Sigma$
baryons[fn::Baryons are bound states of three quarks. The name is
derived from the greek word "heavy" or "barus" ]. This coupled with
the discoveries of the $K$, $\pi$ and $\eta$ mesons[fn:: Mesons are
bound states of a quark and an anti-quark. The name is derived from
the greek word "intermediate" or "mesos" ] lead to the proposal of the
"eightfold way" \cite{PhysRev.125.1067}. The guiding principal of the
eightfold way is to use the structure of a proposed $SU(3)\times
SU(3)$ symmetry to explain the mesons and baryons known to date and to
make strong predictions about new states that should be observed
\cite{PhysRev.125.1067}. This organization of the particles hints at
the existence of fundamental particles called /quarks/.

While the eightfold way provided an organizational scheme and strong
predictions of the relationships between the members of the baryon
octet, experimental evidence for the existence of quarks came later.
In 1971, Feynman published what is now known as the parton[fn:: Parton
so called for being a "part" of the hadron. Also rumored to be named
after Dolly Parton, the country singer \cite{ashone}. ] model of the
hadron \cite{PhysRevD.3.2706}. This model treated the components of
the hadron as fundamental particles with physical properties. This is
in contrast with the quark model of the eightfold way which did not
describe quarks as physical particles. The parton model described many
experimental results to a reasonable degree however there were some
issues, namely a "fudge factor" to bring the calculations close enough
to their experimental values to be compared \cite{PhysRevD.3.2706}.

The eightfold way and the parton model provided two complementary
views of the structure of the hadron. The eightfold way provided a
computational framework that was successful in describing many
observed patterns in the quantum numbers of the known hadrons. The
parton model provided a physical picture for the structure of the
hadron. Neither model provided a precise description of the underlying
dynamics of the strong interaction.

In November, 1973 Wilczek and Gross published their seminal paper on
asymptotically free gauge theories \cite{PhysRevD.8.3633}. This paper
laid the groundwork for what would become quantum chromodynamics (QCD)
the theory underpinning the subject of this thesis. A year later in
1974 the discovery of a new particle was announced independently by a
group at Brookhaven National Lab (named the $J$) and a group at the
Stanford Linear Accelerator (named the $\psi$)
\cite{PhysRevLett.33.1404}\cite{PhysRevLett.33.1406}. The joint
discovery of the J/\psi lead to what is known colloquially as the
"November revolution." The new particle provided a new piece of
experimental evidence that confirmed the picture of quarks and helped
to unravel the mysteries of the strong interaction.

We now understand that hadrons are made up of quarks and gluons
(partons in Feynman's parlance). In addition, the bound state of a
quark and anti-quark of the same flavor are referred to as quarkonium.
This name is reminiscent of positronium, the eletromagnetically bound
state of a positron and electron. Many of the salient features of
quarkonium mass spectrum can be understood with non-relativistic
quantum mechanics and empirical models of the QCD potential. Even with
this deep understanding of nature's fundamental interactions, the
J/\psi particle continues to perplex and confuse our understanding of
QCD. In 1992, the CDF collaboration at the Tevatron reported the first
measurement of J/\psi and \psi(2S) production. They found the rate of
production to be an order of magnitude more than the expectation from
theory \cite{Abe:1992ww}. Two years later, Bodwin, Braaten and Lepage
worked out many of the details of quarkonium production in QCD using
effective field theory \cite{Bodwin:1994jh}.

In 1997, the Tevatron updated its observation of the \psi system with
more data. It reported the differential cross section of the J/\psi to
be much higher than anticipated by the leading order theory
calculation for singlet production \cite{PhysRevLett.79.572}. The
details worked out by Bodwin et al positioned the theory community to
quickly calculate the needed contributions from the non-relativistic
expansion of QCD (NRQCD) in order to describe the data
\cite{PhysRevD.55.R5269}.

The extra NRQCD components that describe the observed transverse
momentum spectrum predicted that the spin alignment between the J/\psi
and the decaying muons be strongly polarized. Subsequent measurements
of the polarization at CDF find no evidence of polarized
spin-alignment in the J/\psi system \cite{PhysRevLett.85.2886}. This
problem has been dubbed the "polarization puzzle" in literature and
has no satisfying explanation nearly two decades after its first
observation.

The production of charm quark pairs which transition to the J/\psi
state probes two complementary energy scales. The origination of the
pair happens during the primary interaction of two partons. This is a
high energy interaction, and can be calculated using perturbation
theory. After the pair of quarks is produced, their relative motion
determines the dynamics of the bound state. This is at a much lower
energy scale and is non-perturbative. Handling these two scales is the
major theoretical challenge to calculating a quantitative cross
section for quarkonium production.

While there has been much theoretical work to understand J/\psi
production, experimental approaches have mainly focused on measuring
the differential production cross section of isolated, directly
produced J/\psi particles. Little to no attention has been paid to the
hadronic environment surrounding the charmonium system. If the
charmonium is produced in a color singlet state, the surrounding
radiation should be less than a charmonium state in a color octet
state.  

A useful phenomenological model employed by Pythia [fn:: A generic
Monte Carlo simulation program used in High Energy Physics] is to
consider the charmonium system as a color-charged particle which can
couple to gluons using rules of QCD \cite{Sjostrand:2007gs}. As this
particle propogates it emits co-linear gluon radiation according to a
splitting function for the process $q \rightarrow q g$. When the
composite particle falls below a certain threshold, it transitions to
a color singlet J/\psi hadron and emits the remaining color charge as
a soft gluon which is incorporated into the underlying event. This is
in contrast to color singlet production which has the J/\psi produced
directly and no net color charge.

An alternative view of charmonium production is the production of the
charm quark pair during the fragmentation of partons into individual
hadrons. In the fragmenting jet[fn:: A jet is a collimated spray of
particles resulting from high energy QCD processes] function (FJF)
framework \cite{Procura:2009vm}, the total cross section is a product
of the short distance partonic cross section with universal
fragmentation functions which determine the evolution of individual
partons to hadrons.

The FJF framework differs from the Pythia model in how it treats the
distribution of radiation around the charmonium system.  In the FJF
approach, a high energy gluon splits according to a splitting function
for $g \rightarrow g g$, which is very different from Pythia's model
which allows the charmonium system to radiate according to a splitting
function for $q \rightarrow q g$.  This leads to fundamentally
different distributions of momentum between the surrounding radiation
and the charmonium system \cite{Bain:2016clc}.  

The following is a birds-eye view of the remainder of the thesis.
Chapter \ref{chap:theory} presents an overview of Quantum
Chromodynamics, and the phenomena relevant for this work. Following
that Chapter \ref{chap:detector} describes the LHC and
\acrshort{atlas} detector in detail. After describing the detecting
apparatus, the methods of reconstructing jets and J/\psi candidates is
described in Chapter \ref{chap:reconstruction}. With a firm grasp of
the theory and physical measurement of the particles, the next step is
a description of the data analysis methods used in Chapter
\ref{chap:analysis}. In Chapter \ref{chap:measurement} the selection
criteria, systematic errors, and final results are presented. A
discussion of consequences and future work follows in Chapter
\ref{chap:conclusion}.

#+LaTeX: \chapter{Theory}
#+LaTeX: \label{chap:theory}
* Quantum Chromodynamics
Quantum chromodynamics describes the interactions between quarks and
gluons. It is one of the fundamental pieces of the Standard Model of
Physics, and has provided fertile ground for experimental and
theoretical work. The interactions of QCD are determined by the SU(3)
symmetry group. Under this symmetry quarks have a color charge
($a=1,2,3$). While quarks carry a color charge, they must form color
neutral particles. Therefore, it is useful to assign the colors red,
green, and blue to the color index in order to provide intuition for
which states are allowed. Quarks paired with color conjugated quarks
(green with anti-green, red with anti-red etc) form the mesons.
Triplet pairs of quarks with an anti-symmetric combination of red,
green, and blue form color neutral baryons. Other more exotic
combinations are allowed but they must follow the constraint that the
state be color neutral.
** Quark Flavor
In addition to carrying color charge, quarks carry a flavor. The
Standard Model consists of three generations of quarks. Each
generation consists of a flavor doublet with charge 2/3 and charge
-1/3. Quarks with charge 2/3(-1/3) are referred to as up(down)-type
quarks. In each generation, the mass of the quarks are successively
larger. In the first generation, the up and down quarks are a few MeV.
The strange and charm quark masses differ by a factor of 10. The
strange quark mass is approximately 100 MeV, while the charm quark
mass is near 1 GeV. In the third and final generation, the bottom
quark is 4 GeV, and the top quark is forty times larger at 173 GeV
\cite{Agashe:2014kda}. The quantum numbers of the individual quarks
determine the properties of the composite baryons and mesons.
** Lagrangian
The formulation of a quantum theory for quark interactions requires a
lagrangian which contains interaction terms which satisfy the SU(3)
symmetry group. The following summarizes the results in chapter 1 of
"QCD and Collider Physics" \cite{Ellis:1991qj}, for further details
the reader is referred to that text.

In order to derive a quantum theory, begin by writing the QCD
lagrangian in terms of a classical field plus a gauge fixing term, and
a ghost term.
#+BEGIN_LaTeX
  \begin{equation*}
    \mathcal{L}_{\text{QCD}}=\mathcal{L}_{\text{Classical}}+\mathcal{L}_{\text{Gauge}} + \mathcal{L}_{\text{Ghost}}
  \end{equation*}
#+END_LaTeX
In natural units ($\hbar=c=1$), the classical field lagrangian is:
#+BEGIN_LaTeX
  \begin{equation}
  \label{eq:qcd-classic}
    \mathcal{L}_{\text{Classical}} = -\frac{1}{4}F^A_{\alpha\beta}F^{\alpha\beta}_A + \sum_{\text{flavors}}\overline{q}_a(i\slashed{D}-m)_{ab}q_b
  \end{equation}
#+END_LaTeX
Here $\slashed{D}\equiv\gamma_\mu D^\mu$, and $F_{\alpha\beta}^A$ is
the gluon field strength tensor:
#+BEGIN_LaTeX
  \begin{equation}
  \label{eq:qcd-tensor}
    F_{\alpha\beta}^A =
    \partial_\alpha\mathcal{A}_\beta^A-\partial_\beta\mathcal{A}_\alpha^A - g f^{ABC}\mathcal{A}_\alpha^B\mathcal{A}_\beta^C
  \end{equation}
#+END_LaTeX
The color indices $A,B,C$ run over the eight generators of the SU(3)
group. The constant $g$ represents the coupling strength, and the
constants $f^{ABC}$ are the structure constants of SU(3). It is this
term which distinguishes QCD from quantum electrodynamics (QED). In
order to derive the Feynman rules for QCD, the path integral of the
action must be evaluated. In the standard formulation of the action,
the resulting integral is badly divergent because of the gauge
invariance of the theory \cite{Peskin:1995ev} [fn:: See 9.4
Quantization of the Electromagnetic Field]. Following the
Faddeev-Popov method of gauge fixing used in \cite{Ellis:1991qj} the
following two terms are added to the lagrangian:
#+BEGIN_LaTeX
  \begin{align}
    \mathcal{L}_{\text{Gauge}} &= -
    \frac{1}{2\lambda}(\partial^\alpha\mathcal{A}_\alpha^A)^2 \\
    \mathcal{L}_{\text{Ghost}} &= \partial_\alpha\eta^{A\dagger}(D^\alpha_{AB}\eta^B)
  \end{align}
#+END_LaTeX
These terms serve to constrain the integral over the action to
physical configurations exactly once \cite{Peskin:1995ev}. 
** Feyman Rules
The Feynman rules for QCD can be determined from the lagrangian by
finding the action ($S = \int \mathcal{L} d^4x$)and writing it in
terms of a free field lagrangian $S_0$ and an interacting term $S_I$:
#+BEGIN_LaTeX
  \begin{equation*}
  S = S_0 + S_I
  \end{equation*}
#+END_LaTeX
Further by identifying $\partial^\alpha = -ip^\alpha$ as the momentum
it is possible to write down the two point function for the quarks and
gluons. This results in the Feynman rules shown in Figure
\ref{fig:qcd-feyn-rules}.
#+CAPTION: Feynman rules for QCD, see \cite{Ellis:1991qj} for more details.
#+NAME: fig:qcd-feyn-rules
#+ATTR_LATEX: :width \linewidth
[[file:figures/qcd_rules.eps]]

Combined, these rules allow the creation of any relativistic quark
interactions allowed by the theory of QCD.  There are two aspects of
QCD which distinguish it from QED. 

The first is the running of the coupling constant, $\alpha_S$. In QED,
the coupling constant is higher at high energies. This running of the
coupling constant can be understood by examining the state of the
vacuum around the electric charge. At high energies, and short
distances, there is less screening of the true charge of the electron
due to vacuum polarization. This polarization arises due to dipole
pairs of virtual electrons and positrons which screen the charge of
the electron. This leads to a coupling constant which is larger than
at low energies. In QCD, the coupling constant decreases at high
energy.  This phenomenon is known as asymptotic freedom.  At very high
energies, the coupling between quarks becomes so low that they become
free particles.  It is difficult to understand this from the vacuum of
QCD, but it is possible to make analogies to the paramagnetic
properties of the vacuum \cite{Ellis:1991qj}. 

The second feature is the self-interaction of the gluon.  In QED, the
mediating photon has no electric charge, and thus does not couple to
itself.  In QCD, the gluon carries color charge. This means that the
field doesn't spread uniformly out from the quark, instead it forms
tube-like structures.  At some point, the potential energy stored in
the self-interacting gluon tubes becomes so high that it is
energetically favorable to create a quark anti-quark pair from the
vacuum than it is to increase the distance between two quarks further.
This property of QCD is referred to as confinement. 
* Quarkonium
The bound states and their properties are important to any theory of
interactions. In QCD, bound states consist of mesons and baryons in
accordance with the rules outlined in Section [[Feyman Rules]]. When a
meson forms a bound state with a quark and anti-quark of the same
flavor it is referred to as a quarkonium state. This naming scheme is
reminiscent of the positronium bound state from quantum mechanics in a
coulomb potential. Quarkonium have a number of unique properties that
make it an ideal system to study properties of QCD. The bound state
consists of a quark and its charge-conjugate. This provides a degree
of symmetry not present in other meson systems. In heavy quarkonium
systems (charmonium and bottomonium), the mass scale is high enough
that perturbation theory can provide useful answers relative to the
cutoff energy scale $\Lambda_{\text{QCD}}\simeq 450~\text{MeV}$. The
strength of the coupling strength of QCD in the charmonium system is
$\alpha_s(m_c)\approx0.24$ \cite{Bodwin:1994jh}. This is large enough
that the perturbation series converges more slowly than one would
hope. The higher mass of the bottom quark allows the bottomonium
system a faster rate of convergence. At the bottom mass scale,
$\alpha_s(m_b)\approx0.18$ \cite{Bodwin:1994jh}.

Before examining the consequences of a larger $\alpha_s$ in the
charmonium system, it is useful to reproduce as much of the charmonium
spectrum as possible using quantum mechanics. An important aspect of
quarkonium production at high energies in hadronic collisions is the
interplay of multiple energy scales. At very high energies, production
is dominated by the fragmentation of gluons into pairs of charm
quarks. The gluon recoils from a primary interaction with a gluon or
quark in the proton-proton collision. The energy scale which
determines the production of the quark pair is the mass of the heavy
quark $M$.

In the rest frame of the quarkonia's constituent quarks the relative
velocity ($v$) of the quarks is the important scale. This means their
relative momentum ($Mv$) is important for the dynamics of the
quarkonium's propagation and subsequent decay. The final quantity
which determines the dynamics of the system is the kinetic energy
($Mv^2$) of the quarks. The kinetic energy determines the size of the
radial excitations in the system \cite{Bodwin:1994jh}. It is assumed
that these scales are well separated in the sense that $(Mv^2)^2 <<
(Mv)^2 << M^2$ \cite{Bodwin:1994jh}.

** Positronium System
A treatment of the positronium system can be found in any
undergraduate treatment of bound states allowed by the Coulomb
potential \cite{Townsend:2000modern} \cite{Griffiths:2008zz}. A brief
review of the important results are presented. The content of this
section follows that of \cite{Ellis:1991qj} and uses a notation that
makes the analogies between the coulomb potential and the QCD
potential manifest. The existence of a solution is due to the
spherical symmetry of the coulomb potential. This allows the system to
be solved by separation of variables and reduces the degrees of
freedom to finding the one dimensional bound states due to the coulomb
potential:
#+BEGIN_LaTeX
  \begin{equation*}
    U(r) = - \alpha/r
  \end{equation*}
#+END_LaTeX
Here $\alpha$ is the dimensionless fine structure constant, and takes
a value of 1/137. The wavefunction is then written as:
#+BEGIN_LaTeX
\begin{equation}
\psi(r,\theta,\phi) = R_{l,n}(r)Y^m_l(\theta,\phi)
\end{equation}
#+END_LaTeX
Here $R_{l,n}(r)$ is the radial solution, and $Y^m_l(\theta,\phi)$ are
the spherical harmonic functions. The spherical harmonics $Y^m_l$
arise from requiring angular momentum conservation. The radial
functions are determined by finding the solutions to the
time-independent Shroedinger equation. The energy eigenvalues are the
well known Bohr energy levels:
#+BEGIN_LaTeX
\begin{equation}
E_n = - \frac{\mu\alpha^2}{2n^2}
\end{equation}
#+END_LaTeX
Here $\mu$ is the reduced mass of the system[fn:: $\mu\equiv
\frac{m_1m_2}{m_1+m_2}$, In the case of positronium this is $m_e/2$].
The characteristic length scale of the system is the Bohr radius:
#+BEGIN_LaTeX
  \begin{equation}
  a_0 = \frac{1}{\mu \alpha}
  \end{equation}
#+END_LaTeX
The ground state wave function is ($n=1,l=0,m=0$) \cite{Townsend:2000modern}:
#+BEGIN_LaTeX
\begin{equation}
\label{eq:1S1}
\psi_{100}(r,\theta,\phi) = \frac{1}{\sqrt{\pi a_0^3}}e^{-r/a_0}
\end{equation}
#+END_LaTeX
The first radial excited state is ($n=2,l=1,m=0$) \cite{Townsend:2000modern}:
#+BEGIN_LaTeX
  \begin{equation}
  \label{eq:3P0}
  \psi_{210}(r,\theta,\phi) = \frac{1}{4\sqrt{2\pi a_0^3}}\frac{r}{a_0}e^{-r/(2a_0)}\cos\theta
  \end{equation}
#+END_LaTeX
These two states are important because they correspond to the first
two excitations in the charmonium spectrum. At this point it is useful
to introduce the spectroscopic notation used in quarkonia literature.
The notation follows that of atomic spectroscopy: $^{2S+1}L_J$. Here
$S$ is the total spin of the system, $L$ is the orbital quantum
number, and $J$ is total angular momentum. In the case of positronium,
and quarkonium, the constituent particles are spin-1/2. Therefore when
they are combined $S$ can take the values of 0 or 1. The orbital
angular quantum number $L$ follows the time-honored notation where
$L=0,1,2,3,\ldots$ corresponds to the letters $S,P,D,F,\ldots$.
Finally, $J$ takes the values $J=|L-S|,\ldots,L+S$.

Up to this point the positronium system and the quarkonium system have
been treated as interchangeable. In fact, if gluons did not
self-interact, the QED potential and the QCD potential would be the
same modulo coupling constants and a numerical factor for color. This
similarity suggests that using the hydrogen-like wave-functions as a
basis state and applying perturbation theory may prove fruitful.
** Potential Models of QCD
It is not an accident that the potential model of QCD works well to
describe the distribution of bound states observed in quarkonium
systems. First, the gluon interaction times are much shorter than the
movement time scale of the quarks. This is due to the assumption that
the kinetic energy, $Mv^2$ is much smaller than the momentum of the
quarks, $Mv$ \cite{Bodwin:1994jh}. This means that treating the quarks
as though they exist in an instantaneous potential is a good
approximation. The second reason potential models are successful is
the fact that the probability of another gluon existing in the bound
state is small \cite{Bodwin:1994jh}.

Using a the coulomb eigenfunctions as a set of basis states and
applying a perturbative potential provides a good description of the
quarkonium spectrum. The perturbation used is due to the
self-interaction of the gluons. 
#+BEGIN_LaTeX
\begin{equation*}
V(r)=Kr
\end{equation*}
#+END_LaTeX 
Here $K$ is the "string constant".  This term combined with the
coulomb-like potential:
#+BEGIN_LaTeX
  \begin{equation*}
    U(r) = - \frac{4}{3}\frac{\alpha_s}{r}
  \end{equation*}
#+END_LaTeX
completes the model. The perturbation is confining at large distances
and presents a constant force. The string analogy is apt, as the
tension in a string is constant. When the force applied exceeds the
tensile strength of the string, the string snaps. This analogy
suggests the string model of fragmentation in which the gluon
"strings" snap and quark anti-quark pairs form at the ends of the
strings.
#+CAPTION: Spectrum of charmonium and bottomonium bound states compared to potential theory \cite{Ellis:1991qj}.  
#+NAME: fig:spectrum
#+ATTR_LATEX: :width \linewidth :options angle=-90
[[file:figures/quarkonium_spectrum.eps]] 

Figure \ref{fig:spectrum} shows the result of applying a more
sophisticated potential model as a perturbation on the coulomb-like
eigenfunctions. This model has the asymptotic features of the string
model and describes the data well \cite{Ellis:1991qj}.  The dashed
lines are the theory prediction and the solid lines are the data.  The
bottomonium spectrum is better described because the mass is higher,
and hence the coupling constant is weaker making the assumptions
behind the potential model stronger. 
* Non-relativistic QCD
While the potential model of QCD bound states does a good job of
capturing the features of the spectrum it is not a complete
description. Figure \ref{fig:spectrum} shows some disagreement in the
numerical values for the mass eigenstates. Further, the potential
model offers no way of calculating the differential cross section for
production. This can be done using perturbation theory with the
relativistic QCD lagrangian. The leading order cross sections for
J/\psi production were calculated in the early 80s
\cite{Baier:1983va}. After the measurement of the J/\psi and \psi(2S)
by the Tevatron in the early 90s, the disparity between the leading
order prediction and the measured data was large. This lead to the
exploration of effective field theory descriptions of QCD in an
attempt to bridge the gap between the non-perturbative parts of
quarkonia processes which are difficult to calculate and the parts of
quarkonia production amenable to perturbation theory
\cite{Bodwin:1994jh}.
** Lagrangian
Rather than take an explicit expansion of the QCD Lagrangian
(\ref{eq:qcd-classic}), it is informative to build a Lagrangian which
is equivalent to the fully relativistic version. In this case recall
that the non-relativistic expansion for the energy of a particle is
the classical kinetic energy:
#+BEGIN_LaTeX
\begin{equation}
E = \sqrt{M^2+p^2} \simeq M + \frac{p^2}{2M}
\end{equation}
#+END_LaTeX
The separation of short distance interactions of the light quarks and
the long distance interactions of the heavy quarks suggest the
following terms in the NRQCD lagrangian \cite{Bodwin:1994jh}:
#+BEGIN_LaTeX
\begin{equation}
\mathcal{L}_{\text{NRQCD}} = \mathcal{L}_{\text{light}} + \mathcal{L}_{\text{heavy}} + \delta\mathcal{L}
\end{equation}
#+END_LaTeX
The light quarks are expected to be adequately described by the QCD
lagrangian, and so those terms are retained:
#+BEGIN_LaTeX
  \begin{equation}
    \mathcal{L}_{\text{light}} = -\frac{1}{2}F^A_{\alpha\beta}F^{\alpha\beta}_A + \sum_{\text{light flavors}}\overline{q}_a(i\slashed{D}-m)_{ab}q_b
  \end{equation}
#+END_LaTeX
The heavy quarks are explicitly inserted using the non-relativistic
expansion of the gauge-covariant derivative:
#+BEGIN_LaTeX
\begin{equation}
i\slashed{D} - m  = i D_t + \frac{\mathbf{D}^2}{2M}
\end{equation}
#+END_LaTeX
This gives:
#+BEGIN_LaTeX
\begin{equation}
\mathcal{L}_{\text{heavy}} = \psi^\dagger\left(iD_t + \frac{\mathbf{D}^2}{2M}\right)\psi + \chi^\dagger\left(iD_t - \frac{\mathbf{D}^2}{2m}\right)\chi 
\end{equation}
#+END_LaTeX
Where the color and spin indices have now been supressed and $\psi$ is
the Pauli spinor field responsible for annihilating a heavy quark.
Conversely $\chi$ is the Pauli spinor field for creating a heavy
anti-quark, $D_t$ and $\mathbf{D}$ are the space-time components of
the gauge covariant derivative $D^\mu$.  

These two terms together describe QCD coupled with a Schrödinger
theory for the heavy quarks \cite{Bodwin:1994jh}.  Since the
Schrödinger terms were added as a non-relativistic expansion of the
gauge-covariant derivative additional terms in the expansion must be
included in order to fully describe the relativistic effects of QCD.
These terms are explained in detail in \cite{Bodwin:1994jh} and are
contained in the $\delta\mathcal{L}$ term above.  

Organizing the lagrangian in this way allows cross section formulas to
be written as a dual expansion in the relative velocities of the heavy
quarks and the QCD coupling constant $\alpha_s$.  This gives insight
into which effects dominate at what scale in the short and long
distance interactions.  
** Factorization Theorem
Because this formulation of the lagrangian makes the Schrödinger
states explicit, the quarkonium state can be interpreted as a sum of
all possible Fock state configurations.  This can be written as
\cite{Ellis:1991qj}:
#+BEGIN_LaTeX
\begin{equation}
  \begin{aligned}
  |\psi_Q \rangle &= O(1)|Q\overline{Q}[^3S_1^{(1)}]\rangle + O(v) |Q\overline{Q}[^3P_J^{(8)}]g \rangle \\
  &+ O(v^2)|Q\overline{Q}[^1S_0^{(8)}]g \rangle + O(v^2)|Q\overline{Q}[^3S_1^{(1,8)}]gg \rangle \\
  &+ O(v^2)|Q\overline{Q}[^3D_J^{(1,8)}]gg \rangle + \ldots \\
  \end{aligned}
\end{equation}
#+END_LaTeX
Here $\psi_Q$ is the quarkonium bound state.  The angular momentum
quantum numbers of the Fock state are given in standard spectroscopic
notation: $^{2S+1}L_J^{(1,8)}$ with an additional index to indicate singlet
(1) or octet (8) color states.  In this notation $S$ is the spin of
the system, $L$ is the orbital quantum number and $J$ is the total
angular momentum. This formula also makes explicit the relative
probability of finding a gluon in a $Q\overline{Q}$ state, which was one of
the conditions necessary for the potential model of quarkonium.

The leading order term corresponds to the wavefunction from the
Schrödinger picture.  Higher order terms correspond to Fock states
which provide a soft gluon.  The presence of this gluon in the state
allows the quarkonium to be in a color octet state.  The inclusion of
these terms in the expression for the overall cross section provides
important contributions to the production of quarkonia in hadronic
collisions.  

The explicit formulation of the partonic cross section can be written
as: 
#+BEGIN_LaTeX
  \begin{equation}
  \label{eq:xs_total}
  \frac{d\sigma}{d\hat{t}}(ab \rightarrow Q\overline{Q}[n] c \rightarrow
  \psi_Q) = \frac{1}{16 \pi \hat{s}^2}
  \overline{\sum}\left|\mathcal{A}(ab \rightarrow Q\overline{Q}[n] c)_{\text{short}}\right|^2\langle 0 | O^{\psi_Q}_{8,1}(n) |0 \rangle
  \end{equation}
#+END_LaTeX
Here, $a,b$ and $c$ represent initial and final state partons, $n$ is
shorthand for the spectroscopic term symbol introduced above, and
$\psi_{Q}$ is the final state quarkonium. The sum is understood to be
the average over initial spin and color states of the scattering
amplitudes[fn:: Amplitudes are related to the probability of a process
occuring] and the $\langle 0 | O^{\psi_Q}_{8,1}(n) |0 \rangle$ term
(abbreviated as $\mathcal{O}^H_{8,1}(n)$) is the known long distance
matrix element (LDME).

Equation \ref{eq:xs_total} explicitly separates the energy scales
involved in production. Figure \ref{fig:nrqcd-ldme} shows a pictoral
representation of this factorization. The short distance amplitude is
calculated by evaluating the relevant Feynman diagrams required to
produce a $Q\overline{Q}$ pair with quantum numbers $n$. The LDME
(repesented by the grey blob) on the other hand represents the low
energy, non-perturbative part of the calculation.

#+CAPTION: Schematic representation of production of quarkonium in NRQCD, $a,b,c=g$ as in \ref{eq:xs_total}. 
#+NAME: fig:nrqcd-ldme
#+ATTR_LATEX: :width 0.5\linewidth
[[file:figures/nrqcd_ldme.eps]] 

This value cannot be calculated directly and must be inferred from
experimental measurements. The extraction of LDMEs from globally
measured data has been done many times \cite{Gong:2012ug}
\cite{Butenschoen:2012qr} \cite{Faccioli:2014cqa}, but the methodology
is fraught with pitfalls and there is no definitive set available.
Further, the LDMEs represent a large number of degrees of freedom.
Some components have different momentum dependence, and thus it is
possible to re-weight them to fit the subset of data judged valid by
the person fitting the parameters.

The LDME values extracted are validated using the only degree of
freedom remaining in the quarkonium system: the spin alignment between
the quarkonium and the measured decay products. Historically the
disagreement between the measured spin-alignment and the amount
required by the extracted LDMEs has been referred to as the
"polarization puzzle[fn:: The alliteration seems to have contributed
to the persistency of this name versus the more technically accurate
"spin-alignment inconsistency"]." There have been many attempts at
explaining the effect \cite{Haberzettl:2007kj} \cite{Ma:2010yw}
\cite{Chao:2012iv} \cite{Lansberg:2013wva}, but none are completely
satisfactory.

* Jet fragmentation
Having examined the bound states QCD is capable of producing, it is
now useful examine another aspect of QCD at a different energy scale:
the fate of a recoiling parton in a hard[fn:: Hard here refers to high
energy, conversely soft refers to low energy.] interaction.
Confinement makes it impossible for a parton to propagate through
space without forming a color singlet state. What is needed is a
framework for discussing the transition between a single hard parton
and the shower of hadrons ultimately measured in the detector as a
jet.

As in the production of quarkonium states there are two energy scales
which must be separated to make progress with the QCD processes.  The
scale where perturbation theory can be applied is separated into what
is called the parton shower.  The non-perturbative part of the process
is the transition from partons into hadrons referred to as
hadronization.  
** Parton Shower
#+BEGIN_LaTeX
  \begin{figure}[htp]
    \centering
    \subfloat[$g \rightarrow gg$]{
      \label{fig:g-to-gg}
      \includegraphics[width=0.4\textwidth]{figures/g_to_gg.eps}
    }\qquad
    \subfloat[$g \rightarrow q\overline{q}$]{
      \label{fig:g-to-qqbar}
      \includegraphics[width=0.4\textwidth]{figures/g_to_qqbar.eps}
    }\qquad
    \subfloat[$q \rightarrow qg$]{
      \label{fig:g-to-qg}
      \includegraphics[width=0.4\textwidth]{figures/q_to_qg.eps}
    }
    \caption{\label{fig:parton-splittings} Feynman vertices that contribute to a parton shower.}
  \end{figure}
#+END_LaTeX
Figure \ref{fig:parton-splittings} shows the various initial and final
state parton configurations which contribute to a parton shower. An
entire shower consists of a series of splittings following different
probability distributions depending on the outgoing partons at each
splitting. The process is dissipative, in the sense that the energy is
shared between the final state partons, and at each branching the
energy of a given parton is less than the previous branching's
daughters.  When the final state partons fall below a certain
threshold the non-perturbative effects of hadronization take over and
the partons form hadrons which are ultimately detected by the
experimental apparatus. 

The parton splitting functions have characteristic differences that
affect the outcome of the shower. Following Chapter 5 of
\cite{Ellis:1991qj}, the shower is assumed to follow timelike
branching. The energy fraction $z$ of branching is defined as:
#+BEGIN_LaTeX
\begin{equation}
z = E_c/E_a = 1 - E_b/E_a
\end{equation}
#+END_LaTeX
After averaging over the possible polarization states of the incoming
and outgoing gluons the amplitude for splitting from $n$ partons to
$n+1$ partons is given by:
#+BEGIN_LaTeX
\begin{equation}
|\mathcal{M}_{n+1}|^2 \sim \frac{4g^2}{t}\hat{P}_{bc}(z)|\mathcal{M}_n|^2
\end{equation}
#+END_LaTeX
Here $g$ is the QCD coupling constant, $t\equiv p_a^2$ and
$\hat{P}_{bc}$ is the unregularized splitting function for the final
state partons. The gluon splitting function corresponding to Figure
\ref{fig:g-to-gg} is:
#+BEGIN_LaTeX
\begin{equation}
\label{eq:gg-split}
\hat{P}_{gg}(z) = C_A\left[\frac{1-z}{z}+\frac{z}{1-z}+z(1-z)\right]
\end{equation}
#+END_LaTeX
Here the color factor is $C_A=3$. It is useful to take the various
limits. Notice that when one of the partons is soft either ($c$ soft)
$z \rightarrow 0$ or ($b$ soft) $z \rightarrow 1$. The first term of
equation \ref{eq:gg-split} is divergent for $z \rightarrow 0$. The same
is true for the second term as $z \rightarrow 1$. These divergences
favor soft emission of gluons.

Following the same prescription, the splitting function for gluon
emission from a quark (see Figure \ref{fig:g-to-qg}):
#+BEGIN_LaTeX
\begin{equation}
\hat{P}_{qg}(z) = T_R[z^2+(1-z)^2]
\end{equation}
#+END_LaTeX
In this case the color factor $T_R=1/2$, taking $z \rightarrow 0$
favors soft gluon emission whereas the $z \rightarrow 1$ limit favors
hard emission of the gluon. The parabolic nature of the function
favors one extreme or the other.

The remaining case corresponds to Figure \ref{fig:g-to-qqbar} and is
for a gluon splitting into a quark anti-quark pair.  The spin-averaged
splitting function is:
#+BEGIN_LaTeX
\begin{equation}
\hat{P}_{qq}(z) = C_F \frac{1+z^2}{1-z}
\end{equation}
#+END_LaTeX
This function is unique among the splitting functions in that it
favors one of the outgoing partons to be harder than the other. Figure
\ref{fig:splitting-functions} shows the three splitting functions
defined above.  An arbitrary normalization is applied to the $P_{qq}$
and $P_{gg}$ functions in order to better compare the behavior of the
shapes.
#+CAPTION: The splitting functions required for a parton shower.  An arbitrary normalization is applied to $P_{qq}$ and $P_{gg}$ in order to allow better comparison of the shapes.
#+NAME: fig:splitting-functions
#+ATTR_LATEX: :width \linewidth
[[file:figures/splitting_functions.pdf]] 

The contributions from these individual diagrams and splitting
functions can be used to simulate a parton shower. An example parton
shower from an $e^+e^-$ annihilation event taken from
\cite{Ellis:1991qj} is shown in Figure \ref{fig:parton-shower}.

#+CAPTION: An example parton shower from an $e^+e^-$ annihilation event. Figure taken from \cite{Ellis:1991qj}. 
#+NAME: fig:parton-shower
#+ATTR_LATEX: :width 0.5\linewidth :options  angle=-90
[[file:figures/parton-shower.eps]] 
** Hadronization
The evolution of the partons created during the shower into hadrons is
inherently non-perturbative. The phenomenological model used by Pythia
is the Lund string model \cite{Sjostrand:2007gs}. This model extends
the string analogy developed in Section [[Potential Models of QCD]]. The
idea is that hadrons in the shower are connected via color-strings. If
the energy stored in the string rises above the threshold to produce a
$q\overline{q}$ pair, the string snaps and the process is repeated
until the energies of the remaining string segments fall below a
threshold value. Below this threshold, the string fragments form the
final state hadrons.

If there are gluons present in the final state of the parton shower,
they are connected to the color-strings as dynamical kinks in the
string (see the upper part of the shower in Figure
\ref{fig:color-hadronization}). Figure \ref{fig:color-hadronization}
shows an example of this process in an $e^+e^-$ event
\cite{Ellis:1991qj}. When a gluon splits perturbatively into a pair of
quarks it creates another string segment \cite{Ellis:1991qj}. The
lines outgoing from the grey string segments represent the subsequent
fragmentation of the string as described above. With a complete
description of QCD, the allowed bound states, and the transition from
a high energy parton to the hadrons ultimately measured by the
detector it is time to discuss the actual measurement of particles at
the Large Hadron Collider.
#+CAPTION: String model of hadronization in an $e^+e^-$ event. Grey shaded region is the string. Figure taken from \cite{Ellis:1991qj}
#+NAME: fig:color-hadronization
#+ATTR_LATEX: :width 0.5\linewidth 
[[file:figures/color_hadronization.eps]] 


#+LaTeX: \chapter{The ATLAS detector}
#+LaTeX: \label{chap:detector}
* The Large Hadron Collider
The Large Hadron Collider (LHC) is the largest (in size and energy)
circular hadron collider in existence. The circumference of the
colliding rings is 26.7 km and is buried between 45 m and 170 m below
parts of Switzerland and France \cite{lhc-machine}. The LHC was built
based on infrastructure developed for the Large Electron Positron
collider and utilizes the CERN accelerator complex in order to boost
protons to the high energies required for circulating in the LHC
tunnel. The LHC circulates beams of protons in opposite directions and
steers them into each other at four points around the accelerator
ring. These four points are the sites of the major LHC experiments,
CMS, ATLAS, LHCb, and ALICE \cite{lhc-machine}. The data for this work
was recorded in 2012 when the machine was configured to run each beam
of protons at 4 TeV each for a center of mass energy $\sqrt{s}=8$ TeV.

In order to collide protons, the LHC accelerates them through a series
of booster rings until they are injected into the main accelerator
complex. Protons injected into the LHC are organized into bunches of
10^11 protons. The bunches are spaced according to the frequency (400
MHz) of the RF cavities which accelerate the particles. During the
first run of the LHC, the bunches were spaced 50 ns apart which is
twice the designed bunch spacing of 25 ns.

In order to achieve this configuration of bunch crossings as well as
precise control of the proton beams a number of problems must be
addressed. Foremost is the bending the protons around the ring. This
is achieved using 1,232 superconducting magnetic dipoles
\cite{lhc-machine}. Each of these dipoles is operated at 1.9 K and
produce a field strength of 8 T. The operating temperature of the
magnets has a tight margin above which the superconductivity is lost
and the magnet ceases to conduct \cite{lhc-machine}. This transition
is known as quenching, and when it occurs all of the energy stored in
the field is released. An unintended quench in 2008 led to a massive
helium explosion and delayed the experiment by a year.

Another aspect that is important to the smooth operation of the LHC is
the vacuum in the beam pipe. In order to maximize beam lifetime and
minimize experimental backgrounds the beam pipe must be kept as
pristine as possible. This equates to a vacuum pressure of 10^{-10}
mbar. In the regions around the experiments the vacuum is designed to
keep the density of hydrogen below 10^13 H_2 m^{-3}. As a point of
reference the volume of beampipe contained by the ATLAS detector is
roughly 0.008 m^3. This means that there is roughly $8\times 10^{10}$
hydrogen atoms in the ATLAS beampipe at any given time. The same
volume of hydrogen gas at STP results in $2.15\times 10^{24}$ atoms.
This is a change in concentration of roughly 30 parts per quadrillion.

** Luminosity
Many of the measurements made at the LHC boil down to counting
experiments answering the question: "How many particles with
properties $x$, $y$, and $z$ do I see?" These properties may be the
transverse momentum ($p_T$), invariant mass ($m$), or rapidity ($y$).
The experimental physicist reconstructs events, selects those matching
the required criteria and compares the number counted to a theoretical
calculation.  

Conversely, a theoretical physicist calculates the number of observed
particles with given properties $x$, $y$ and $z$ by starting with
incoming protons and working out the probability of observing the
expected particles. The proton beams are characterized by a parameter
called the luminosity $L$ of the beam which is the particles passing
per second per unit area. When a theoretical physicist calculates the
cross sectional area[fn:: This quantity has SI units of cm^2 but barns
are most commonly used in the field. The name comes from the saying
"you couldn't hit the broad side of a barn" and originated during
research into the atomic bomb \cite{unc-dict}. Another unit from this
era is the "shake" as in "two shakes of a lamb's tail" which is 10 ns,
a convenient unit of measure in nuclear reactions \cite{unc-dict}. ]
of a process ($\sigma(pp \rightarrow A B)$ where $A$ and $B$ are
outgoing particle species), the rate of particles produced is given by
the product of the luminosity and the cross section:
#+BEGIN_LaTeX
\begin{equation*}
dN/dt = L(t) \sigma(pp \rightarrow A B)
\end{equation*}
#+END_LaTeX
In order to predict the absolute number of events, this expression
must be integrated over the time that data was collected:
#+BEGIN_LaTeX
\begin{equation*}
N = \sigma \int L(t)dt
\end{equation*}
#+END_LaTeX
The amount of data collected by the experiment is measured in the
integrated luminosity. It has units of inverse barns which is
convenient for back-of-the-envelope calculations of the expected
number of events for a process: take the product of the data collected
and the expected cross section to get the number of events.

The instantaneous luminosity $L$ of the LHC is given by the following
formula:
#+BEGIN_LaTeX
\begin{equation}
L = \frac{N_b^2n_b f_{\text{rev}}\gamma_r}{4\pi \epsilon_n \beta^*}F
\end{equation}
#+END_LaTeX
The denominator of this equation is fairly straightforward, $N_b$ is
the number of protons per bunch (typically $N_b\sim10^{11}$), $n_b$ is
the number of bunches per beam, $f_{\text{rev}}$ is the revolution
frequency of the machine, $\gamma_r$ is the relativistic gamma factor
for the bunches and $F$ is a geometric factor to account for the
geometry of the crossing angle at the interaction point (IP). The
denominator must be a unit of area from dimensional analysis. The
transverse beam emittance is given by $\epsilon_n$ and $\beta^*$ is
the value of the $\beta$ function at the IP. The two parameters
$\epsilon_n$ and $\beta$ describe the major and semi-major axes of an
ellipse which describes the transverse phase-space profile of the LHC
beam. Together they describe the effective area of the beam at the IP
\cite{lhc-machine}.

The geometric factor $F$ can be worked out from small angle
approximations as well as the RMS length and transverse width of the
beam:
#+BEGIN_LaTeX
\begin{equation}
F = \left(1 + \left(\frac{\theta_c\sigma_z}{2\sigma^*}\right)^2\right)^{-1/2}
\end{equation}
#+END_LaTeX
Here $\theta_c$ is the crossing angle, $\sigma_z$ is the RMS length of
a bunch crossing and $\sigma^*$ is the transverse RMS beam size for a
gaussian beam.  

When the beams cross, there is a high probability that multiple high
energy interactions take place. The interaction which is selected for
study is referred to as the primary interaction. Secondary
interactions contribute to experimental background which are referred
to as pileup. The degree of pileup can be measure by the average
number of interactions per bunch crossing ($\langle\mu \rangle$). For
the data used in this thesis, the pileup was 20 interactions per bunch
crossing on average. Pileup presents an experimental challenge because
the particles produced in association with the events can confuse the
reconstruction algorithms used. This analysis makes use of
reconstructed quantities that are largely insensitive to pileup
effects.

* The ATLAS detector
\acrlong{atlas} (\acrshort{atlas}[fn:: ATLHCA doesn't have the same ring,
or status as a greek titan]) is one of the general purpose detectors
at the LHC. It is located at Point 1 on the LHC ring. Figure
\ref{fig:atlas-detector} shows a high level drawing of the detector,
the detector itself is 44m long and 25 m tall[fn:: The detector weighs
approximately 7000 tonnes. If the volume the detector contains were
hermetically sealed, the density of the detector would allow it to
float if it were put in fresh water.]. The ATLAS detector contains
many detector subsystems which allow it to detect and reconstruct
particles which are created during collisions at the IP. The detectors
all work on the principal that when a charged particle moves through
matter it either radiates energy in the form of Brehmsstrahlung or it
ionizes the surrounding matter. In the former case, the radiation can
be detected directly, or it can produce a positron and electron pair
(pair production) which can be subsequently detected. Different parts of
the detector exploit these two processes in different ways. The
electromagnetic and hadronic calorimeters work to stop electrons and
hadrons while accurately measuring the energy of the incident
particle. Tracking elements aim to accurately detect the time and
location where a charged particle passes and do so in different ways. 
#+CAPTION: A cutaway of the ATLAS detector.  Two small people are shown to scale.
#+NAME: fig:atlas-detector
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/full_atlas_detector.jpeg]] 

In order to accurately measure the charge and momentum of particles
passing through the detector, a set of magnets is used to bend the
charged particles. ATLAS uses a unique configuration of a 2.0 T
solenoid covering the inner detector and a toroidal configuration of 8
superconducting yokes which provide a field between 0.5 T and 1.0 T
\cite{atlas-detector}. The central solenoid ensures that charged
particles bend in the transverse plane of the inner detector. The
toroidal configuration of the outer magnets bend the muons which exit
the hadronic calorimeter, allowing for a precise measurement of the
three spatial components of their momentum. Together these systems
allow the measurement of the particles four momentum and charge. This
analysis exclusively uses charged particle tracks in the form of muon
identified tracks, and inner detector tracks. This was done in order
to minimize various systematic effects that will be discussed.

ATLAS uses a right-handed cylindrical coordinate system with the
$z$-axis oriented along the beam line, see \ref{fig:coord-system} for
details. In cartesian coordinates, the $x$ and $y$ axes are in the
plane transverse to the beam line. The $x$ axis points to the center
of the ring and the $y$ axis points to the Earth's surface. A useful
quantity for describing angles in the detector is pseudorapidity
($\eta$)[fn:: Differences in pseudorapidity are invariant in
relativistic boosts along the beam axis which is very useful
experimentally. ] defined as $\eta\equiv -\log(\tan(\theta/2))$.  In
this variable, the beam line is $\eta\approx4.2$, while the $y$ axis
corresponds to $\eta=0$. 
#+CAPTION: The ATLAS detector's coordinate system, see text for definition of pseudorapidity ($\eta$). 
#+NAME: fig:coord-system
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/atlas_coord.pdf]] 
** Inner Detector
Figure \ref{fig:inner-detector} shows the inner detector at ATLAS with
each subsystem labeled. Figure \ref{fig:inner-detector-slice} shows a
view of the inner detector for a wedge of the detector. Working radially outward from the IP, the
ATLAS inner detector is comprised of three main components: the pixel
detector (extending 45.5 mm $< R <$ 242 mm), the silicon strip
detector (SCT) (extending 255 mm $< R <$ 549 mm), and the transition
radiation tracker (TRT) (extending 554 mm $< R <$ 1082 mm). The pixel
detector and SCT function based on semi-conductor technologies that
allow them to measure the location of charged particles with high
precision. The TRT operates based on transition radiation, a
phenomenon that occurs when charged particles traverse different
materials. During the transition between materials particles are very
likely to emit radiation which is subsequently detected. Table
\ref{tab:nom-id-accuracy} shows the intrinsic accuracy of the inner
detector subsystems and their alignment tolerances. 
#+CAPTION: The ATLAS inner detector taken from \cite{pixel-detector}. 
#+NAME: fig:inner-detector
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/IDLabeled.eps]] 

#+CAPTION: A different view of the ATLAS inner detector taken from \cite{atlas-detector}. This shows the geometry of the pixel and SCT detectors focusing on the end caps and the TRT end cap.
#+NAME: fig:inner-detector-slice
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/inner_detector_section.png]] 

#+CAPTION: Intrinsic accuracy and alignment tolerances of the inner detector. The lower accuracy of the axial dimension in the SCT is due to the intrinsic pitch of the SCT modules. The axial accuracy of the pixel detector is driven by fabrication constraints \cite{atlas-detector}.
#+NAME: tab:nom-id-accuracy
|---------------+-------------------------+------------+-----------+------------------|
|               | Intrinsic Accuracy      |  Alignment | Tolerance |        ($\mu m$) |
| Subsystem     | ($\mu m$)               | Radial (R) | Axial (z) | Azimuth (R-\phi) |
| /             | <                       |          < |           |                  |
|---------------+-------------------------+------------+-----------+------------------|
| *Pixel*       |                         |            |           |                  |
| Layer-0       | 10 ($R-\phi$) 115 ($z$) |         10 |        20 |                7 |
| Layer-1 and 2 | 10 ($R-\phi$) 115 ($z$) |         20 |        20 |                7 |
| End cap       | 10 ($R-\phi$) 115 ($R$) |         20 |       100 |                7 |
| *SCT*         |                         |            |           |                  |
| Barrel        | 17 ($R-\phi$) 580 ($z$) |        100 |        50 |               12 |
| End cap       | 17 ($R-\phi$) 580 ($R$) |         50 |       200 |               12 |
| *TRT*         | 130                     |            |           |               30 |
|---------------+-------------------------+------------+-----------+------------------|
*** Semiconductor based detectors
The pixel detector and the silicon strip tracker utilize the
ionization of matter as charged particles pass through the active
regions. The active region of the detectors is constructed by forming
a layer of n-doped and p-doped semiconductor. These layers are held at
a fixed voltage. When a charged particle traverses the active region,
the ionized material becomes conducting allowing for the location of
the particle to be determined. Figure \ref{fig:pixel-schematic} shows
a schematic of a pixel. The bottom half of the schematic is the
sensing region and the dark grey and lighter grey regions represent
the doped semiconductor. The bump-bond indicates a fabrication
technique utilized to provide uniform attachment of each
micro-fabricated pixel to the readout electronics.
#+CAPTION: Conceptual diagram of the pixel assembly with a charged particle traversing it \cite{pixel-detector}.
#+NAME: fig:pixel-schematic
#+ATTR_LATEX: :width 0.45\linewidth 
[[file:figures/pixel-cartoon.eps]] 

*** Pixel Detector
The fundamental unit of the pixel detector is a module. Figure
\ref{fig:module-overview} shows the various layers that go into the a
pixel module. A module consists of readout electronics and active
pixel sensors which detect the position of charged particles. Each
module has a sensitive surface $6.08 \times 1.64 \text{cm}^2$
\cite{pixel-detector}. Each module consists of 47232 pixels
\cite{pixel-detector}. The entire pixel detector is constructed from
1744 modules \cite{pixel-detector}. These modules are arranged in
three concentric cylinders. The forward region of the detector is
covered by three rings of end-cap modules on either end of the pixel
barrel region. The geometric arrangement of the modules can be seen
the green components in Figure \ref{fig:inner-detector-slice}. Each
module has three spatial degrees of freedom and two angles which
determine its precise location in space.  Aligning these modules is
critical to achieving an accurate measurement of the particles
momentum when they pass through the inner detector.  Table
\ref{tab:nom-id-accuracy} shows the alignment tolerances of the
pixel detector.
#+CAPTION: Schematic of the module assembly. 47232 pixels are read out from the sensor layer and each one is bump-bonded to the readout electronics \cite{pixel-detector}. 
#+NAME: fig:module-overview
#+ATTR_LATEX: :width 0.75\linewidth 
[[file:figures/Module_overview.eps]] 

*** Silicon Strip Detector
Continuing radially outward is the Silicon Strip Detector (SCT). The
SCT follows the modular design of the pixel detector but with less
axial resolution than the pixel detector. Table
\ref{tab:nom-id-accuracy} shows the nominal resolution and alignment
tolerances of the SCT. Each SCT module has five degrees of freedom
which must be corrected for during alignment and calibration. The SCT
barrel module layout is shown in Figure \ref{fig:sct-module}. One
barrel module has two layers of strips set at a 80 $\mu m$ pitch over
6cm in order to give a trapezoidal geometry \cite{atlas-detector}. The
end cap modules follow a similar construction but a slightly different
geometry in how the strips are arranged. The strips in the end cap
modules are set at various pitches, but have an inter-strip angle in
order to cover the radial plane better \cite{atlas-detector}.
#+CAPTION: Illustration of an SCT barrel module, note the two layers of silicon sensors and their relative pitch.  Each module is 6cm long. Figure taken from \cite{atlas-detector}. 
#+NAME: fig:sct-module
#+ATTR_LATEX: :width 0.75\linewidth 
[[file:figures/sct_barrel_module.png]] 

When charged particles pass through the SCT, they trigger the readout
of various strips within the SCT. If only two strips are read out,
then the approximate location of the particle can be inferred from the
closest crossing of the two strips. If the charged particle passes the
SCT module while another strip is active (which is possible in the
high occupancy environment of ATLAS) an ambiguity arises as to where
the charged particle passed. Figure \ref{fig:sct-strip-geometry} shows
this situation. The trapezoidal geometry creates a large enough
separation between the ambiguous hits that one can be rejected in
favor of the other when information from the other SCT and pixel
layers is taken into account.

#+CAPTION: Illustration of a charged particle interacting with the SCT strips.  Black strips indicate they have been read out, grey are inactive.  When three or more strips are active, an ambiguity in the location of the charged particle arises. 
#+NAME: fig:sct-strip-geometry
#+ATTR_LATEX: :width 0.7\linewidth 
[[file:figures/sct_strip_geometry.pdf]] 

*** Transition Radiation Tracker
The final inner detector subsystem is the transition radiation tracker
(TRT). While the pixel and SCT detectors rely on semiconductor
technology, the TRT utilizes ionization that occurs when a charged
particle traverses material of differing dielectric constants. This
process depends on the species of the charged particle and can be used
in particle identification \cite{Romaniouk:2021497}. For a thorough
review of the physics of transition radiation see
\cite{PhysRevD.12.1289}. Figure \ref{fig:inner-detector} shows the
barrel and end cap TRT. The TRT is constructed from a series of
densely packed 298,304 straw tubes, 4mm in diameter, which each
contain an anode wire at the center \cite{alignment}\cite{trt-barrel}.
The anode is a gold-plated tungsten wire. The gas circulated in the
straw tubes is a gas consisting mostly of xenon. A noble gas is used
in order to reduce the time that ionized particles recombine with
atoms \cite{alignment}. This maximizes the ability to read out when a
charged particle passes through the tube. The interstitial space
between the straw tubes is a polypropylene foam which encourages
charged particles to ionize when the pass through the TRT volume
allowing for the identification of electrons. In the end caps, the
interstitial volume contains foil for the same purpose
\cite{alignment}.

Figure \ref{fig:trt-illustration} shows the geometric lengths involved
in detecting the location of a charged particle \cite{trt-thesis}. As
the charged particle ionizes the gas the free charge flows to the
anode creating a characteristic curve depending on the distance to the
anode. When the collected charge rises above a threshold it is
considered a hit and the time-over-threshold allows the determination
of the radius R in figure \ref{fig:trt-illustration}. This information
is then used for the overall reconstruction of charged particle tracks
in conjunction with the information from the SCT and pixel detectors.
#+CAPTION: As a charged particle ionizes the gas inside the straw
#+CAPTION: tube, charge is collected over time as shown in the blue profiles
#+CAPTION: indicated by the numbers in the straw tubes. When the particle passes
#+CAPTION: closer to the anode the profile of the deposited charge changes
#+CAPTION: \cite{trt-thesis}. Low Treshold (LT) indicates the transition between
#+CAPTION: signal and noise in the event readout.
#+NAME: fig:trt-illustration
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/trt_figure.pdf]] 

During reconstruction the quality of the hits extracted from the
time-over-threshold measurement of the radius must be assessed.
Figure \ref{fig:trt-hit-defs} shows the definition of these hits. When
the estimated drift radius corresponds to where a charged particle
passed it is referred to as a precision hit.  When the charged
particle passes through the tube, but not the estimated radius it is a
tube hit.  When the particle passes outside the tube altogether it is
an outlier and when the tube doesn't register a particle at all it is
a hole \cite{trt-figs}.
#+BEGIN_LaTeX
  \begin{figure}[htp]
    \centering
    \subfloat[]{
      \includegraphics[width=0.4\textwidth]{figures/strawDefs.pdf}
    }\qquad
    \subfloat[]{
      \includegraphics[width=0.8\textwidth]{figures/trt_hit_def.pdf}
    }\qquad \caption{\label{fig:trt-hit-defs} Definition of hit qualities
    used by TRT reconstruction \cite{trt-figs}}
  \end{figure}
#+END_LaTeX
** Calorimeter systems
The calorimeter systems used at ATLAS are shown in Figure
\ref{fig:calorimeter}. ATLAS utilizes various calorimeter technologies
based on stopping particles and measuring the deposited energy.
Calorimeters at ATLAS use an interleaved geometry of scintillation
material and a dense absorbing material for stopping impinging
particles. Scintillation light is collected along fiber optic cables
and read out using photo multipliers. There are two main calorimeter
systems, the electronic calorimeter (ECAL) and the hadronic
calorimeter (HCAL). The ECAL is designed to fully stop and measure
electrons and photons. Hadrons deposit some energy in the ECAL, but
typically make it to the HCAL before fully stopping and depositing
their entire energy.

It is important to note the contrast between how the inner detector
and the calorimeter measures the momentum of particles. The location a
charged particle passes are precisely measured in the inner detector.
This information coupled with the knowledge of the magnetic field the
inner detector is immersed in allows for the measurement of the
particle's three-momentum. In order to fully extract the relativistic
four-momentum a mass hypothesis is assumed[fn:: For charged particles
not associated with electrons, the pion mass is assumed. For tracks
with muon spectrometer information, the muon mass is assumed.]. The
calorimeter works to measure the energy of the impinging particle. For
electrons, the associated inner detector track allows for the
extraction of the four-momentum. For other particles, the energy and
the location in the detector allow the measurement of the particle's
three-momentum. The error on these two measurements is fundamentally
different, and the calibration of the detector is performed in
different ways. This leads to a difference in the energy measured by
charged particles and is the motivation for only using the charged
fraction of hadrons produced in events of interest to this analysis.

#+CAPTION: The ATLAS calorimeter systems
#+NAME: fig:calorimeter
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/calorimeter_labeled.pdf]] 

As with other subsystems in ATLAS, the ECAL consists of separate
barrel and end-cap detectors with slightly different geometries.
Figure \ref{fig:ecal-barrel-module} shows a segment of the ECAL
system. The ECAL utilizes an accordion geometry to ensure that more
than one layer is actively scintillating when an electron or photon is
depositing its energy in the calorimeter this provides full coverage
in the $\phi$ direction. The ECAL is finely segmented in $\eta$
($\Delta \eta = 0.0031$) close to the inner detector and less so in
the bulk of the detector ($\Delta \eta = 0.025$). The end of the ECAL
is covered with coarse "trigger towers" with a segmentation of $\Delta
\eta=0.1$ \cite{atlas-detector}. These towers are used to trigger on
events where a coarse estimate of the event's energy is needed to
decide if the event should be recorded or not. The ECAL's
scintillation material is liquid Argon (LAr), which is chosen for its
intrinsic radiation hardness and its ability to scintillate
\cite{atlas-detector}. Lead is used as the absorber in the ECAL. Lead
is an ideal choice due to its high density and the compact nature of
the ECAL compared to the HCAL.

#+CAPTION: Illustration of the ECAL granularity and geometry of a module \cite{atlas-detector}. 
#+NAME: fig:ecal-barrel-module
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/em_calorimeter_module.pdf]] 

While the ECAL utilizes a accordion geometry, the HCAL utilizes a
slightly different form. The absorption material in the HCAL is steel,
the scintillation material is a plastic based on polystyrene doped
with fluors \cite{atlas-detector}. The HCAL is separated into the
barrel region referred to as the tile calorimeter, and the forward
region covered by the hadronic end-cap calorimeters (HEC). The
calorimeter is segmented into regions of $\Delta \phi \times \Delta
\eta = 0.1 \times 0.1$ for $|\eta| < 2.5$ and $\Delta \phi \times
\Delta \eta = 0.2 \times 0.2$ for larger values of $\eta$
\cite{atlas-detector}. A tile module is shown in Figure
\ref{fig:hcal-barrel-module}. The scintillation light is guided out to
fiber optic cables which are directed to photomultipliers at the top
of the tile unit. The fiber optic cable is 3mm thick and has an
emission peak at 476 nm \cite{atlas-detector}. This means the light
that is optimally transmitted by the cables is a blue-cyan color.
Figure \ref{fig:hcal-endcap} shows the geometry and segmentation of
the a HEC module.

#+BEGIN_LaTeX
  \begin{figure}[htp]
    \centering
    \subfloat[]{
      \label{fig:hcal-barrel-module-phi}
      \includegraphics[width=0.5\textwidth,angle=90]{figures/hcal-barrel-module-azimuth.pdf}
    }
    \subfloat[]{
     \includegraphics[width=0.5\textwidth]{figures/hcal-barrel-module.pdf}
    }\qquad \caption{\label{fig:hcal-barrel-module} Illustration of the
    HCAL module's scintillation and absorber geometry \cite{atlas-detector}. Figure
    \ref{fig:hcal-barrel-module-phi} shows the layout of the tile
    calorimeter from the azimuthal view. }
  \end{figure}
#+END_LaTeX

#+CAPTION: Schematic of a hadronic end cap calorimeter module \cite{atlas-detector}.
#+NAME: fig:hcal-endcap
#+ATTR_LATEX: :width 0.5\linewidth :options  angle=90
[[file:figures/hcal-endcap-module.pdf]] 

** Muon Spectrometer
Many important Standard Model processes decay to two leptons. When
these leptons are electrons, they are reconstructed in the ECAL and
inner detector. When they are muons, they are detected and
reconstructed using the Muon Spectrometer. These detector subsystems
are the outer most portion of ATLAS. Portions of the spectrometer are
immersed in ATLAS's signature toroid shaped magnetic field. The toroid
causes the muons to bend along the $z$ axis allowing for a more
precise measurement of the three-momentum of the particle. The mass of
the muon, relative to the electron, makes it much less likely to
initiate a bremsstrahlung cascade as it passes through the ECAL and
HCAL \cite{Agashe:2014kda}. This allows it to reach the outer region
of the detector where its location can be measured as precisely as
possible. 
#+CAPTION: The muon spectrometer at ATLAS \cite{atlas-detector}
#+NAME: fig:muon-spec
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/muon_system_labeled.pdf]] 

ATLAS utilizes a various detector technologies in order to measure the
momentum of a 1 TeV muon within 10% of its nominal value
\cite{atlas-detector}. To achieve this, the muon spectrometer consists
of monitored drift tubes (MDTs), cathode strip chambers (CSCs),
resistive plate chambers (RPCs) and thin gap chambers (TGCs). Each of
these systems functions differently and serves slightly different
purposes. Figure \ref{fig:muon-spec} shows the muon spectrometer.
Table \ref{tab:muon-spec} lists the relevant numbers and coverage of
the muon spectrometer \cite{atlas-detector}. 
#+CAPTION: Summary of channels and chambers utilized for each subsystem of the Muon Spectrometer at ATLAS \cite{atlas-detector}
#+NAME: tab:muon-spec
|--------------------------+----------------------------------------------------------------|
| *Monitored Drift Tubes*    |                                                                |
| Coverage                 | $\vert\eta\vert < 2.7$ (innermost layer: $\vert\eta\vert~2.0$) |
| Number of chambers       |                                                           1088 |
| Number of channels       |                                                         354000 |
| Function                 |                                             Precision Tracking |
|--------------------------+----------------------------------------------------------------|
| *Cathode Strip Chambers*   |                                                                |
| Coverage                 |                                   $2.0 < \vert\eta\vert < 2.7$ |
| Number of chambers       |                                                             32 |
| Number of channels       |                                                          31000 |
| Function                 |                                             Precision Tracking |
|--------------------------+----------------------------------------------------------------|
| *Resistive plate chambers* |                                                                |
| Coverage                 |                                        $\vert\eta\vert < 1.05$ |
| Number of chambers       |                                                            606 |
| Number of channels       |                                                         373000 |
| Function                 |                                  Triggering, second coordinate |
|--------------------------+----------------------------------------------------------------|
| *Thin Gap Chambers*        |                                                                |
| Coverage                 |             $1.05 < \vert\eta\vert < 2.7$ (2.4 for triggering) |
| Number of chambers       |                                                           3588 |
| Number of channels       |                                                         318000 |
| Function                 |                                  Triggering, second coordinate |
|                          |                                                                | 
 
#+BEGIN_LaTeX
  \begin{figure}[htp]
    \centering
    \subfloat[]{
      \label{fig:ms-transverse}
      \includegraphics[width=0.4\textwidth]{figures/ms-transverse.pdf}
    }
    \subfloat[]{
     \label{fig:ms-longitudinal}
     \includegraphics[width=0.6\textwidth]{figures/ms-longitudinal.pdf}
    }\qquad \caption{\label{fig:ms-layout} Layout of the muon chambers
    in the muon spectrometer. See \cite{atlas-detector} for detailed
    description of the naming scheme, roughly ``B'' stands for Barrel,
    ``E'' for end cap, ``L'' for large, ``S'' for small, and ``I'',
    ``M'', and ``O'' stand for inner, middle, and outer respectively
    \cite{atlas-detector}. Infinite momentum muons would propagate along
    the blue dashed lines. }
  \end{figure}
#+END_LaTeX
*** Monitored Drift Tube
The underlying physics driving the function of the monitored drift
tube is the same as the straw tubes in the TRT. The diameter of the
drift tube is significantly larger (29.970mm) and the gas used is a
mix of CO_2 (7%) and Ar (93%). The central anode is a tungsten-rhenium
wire and is held at 3080V \cite{atlas-detector}. Figure
\ref{fig:ms-mdt} shows the front and side view of the MDT. Figure
\ref{fig:ms-mdt-module} shows how the MDTs fit together to form a
module.
#+BEGIN_LaTeX
  \begin{figure}[htp]
    \centering
    \subfloat[]{
      \includegraphics[width=0.3\textwidth]{figures/MDT_tube_cross_section.pdf}
    }
    \subfloat[]{
     \includegraphics[width=0.7\textwidth]{figures/MDT_tube_longitudinal.pdf}
    }\qquad \caption{\label{fig:ms-mdt} Illustration of a MDT showing
    the cross section and longitudinal views \cite{atlas-detector}. }
  \end{figure}
#+END_LaTeX

#+CAPTION: A schematic of an MDT chamber utilized at atlas.  RO and HV correspond to read out and high voltage locations respectively \cite{atlas-detector}
#+NAME: fig:ms-mdt-module
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/MDT_chamber_schematics.pdf]] 

The green regions in Figure \ref{fig:ms-longitudinal} show the MDT
chambers for the barrel region which are also illustrated in Figure
\ref{fig:ms-mdt-module}. MDTs are also utilized in the light-blue
regions of \ref{fig:ms-longitudinal} as the end-cap chambers. They
utlizes a trapezoidal geometry in order to better measure the radial
location the muon traverses in the forward region
\cite{atlas-detector}.

*** Cathode Strip Chambers
Cathode Strip chambers are utilized in the very forward regions of the
detector as illustrated in the yellow region of Figure
\ref{fig:ms-longitudinal}. This was done because of the CSC's higher
rate capability and time resolution \cite{atlas-detector}. The
geometry of the CSC is shown in figure \ref{fig:csc-geometry}. The CSC
is also required for tagging the time of the beam crossing. This
requires that the time resolution of the detector be very precise.
Integrating a measurement over the layers of the CSC allows the
measurement of the time of arrival with an RMS of 3.6 ns
\cite{atlas-detector}.

#+CAPTION: The geometry of CSC chambers at ATLAS \cite{atlas-detector}.
#+NAME: fig:csc-geometry
#+ATTR_LATEX: :width 0.5\linewidth 
[[file:figures/CSC_geometry.pdf]] 

The name Cathode Strip Chamber implies the detector type used.
Cathode Strip Chambers are a series of cathode strips and anode wires
oriented ninety degrees to each other. The cathodes are segmented to
provide precision measurements of the transverse and longitudinal
directions.  The anode is held at 1900 V relative to the cathode.
When a charged particle ionizes the Ar (80%) CO_2 (20%) mixture, it
creates an avalanche of charge which is measured by the readout
electronics.  Figure \ref{fig:csc-cell} shows the geometric layout of
the anode and cathode strips in a chamber.  Figure
\ref{fig:csc-readout} is an illustration of the charge collected along
the anode and subsequently measured by the readout electronics on the
cathode strips.
#+BEGIN_LaTeX
  \begin{figure}[htp]
    \centering
    \subfloat[]{
    \label{fig:csc-cell}
      \includegraphics[width=0.6\textwidth]{figures/CSC_cell.eps}
    }
    \subfloat[]{
    \label{fig:csc-readout}
     \includegraphics[width=0.4\textwidth]{figures/CSC_readout.eps}
    }\caption{\label{fig:ms-csc-schematic} Left: Illustration of
    CSC cathode and anode wires, The anode width $S$ is the same as the
    anode to cathode distance $d$. Right: Cathode strip width is
    $b=1.519$ mm. The readout pitch $a=5.308$ mm and 5.567 mm
    \cite{atlas-detector}. }
  \end{figure}
#+END_LaTeX

*** Resistive Plate Chambers
While the CSC and MDT utilize technologies to precisely measure the
location of muons passing in the muon spectrometer, resistive plate
chambers (RPCs) and thin gap chambers (TGCs) are primarily used to
trigger on muons by providing a coarse estimate of where and when a
muon traversed the detector. The triggering system in ATLAS is covered
in detail in Section [[Trigger]]. Figure \ref{fig:rpc-tgc-trigger} shows
the RPC and TGC chambers that provide the readouts allowing fast
triggering on muons. The RPC systems are able to trigger on muons with
momentum between 9-35 GeV or 6-9 GeV depending on which system fires
\cite{atlas-detector}. The RPC consists of two layers of dielectric
separated by a 2mm gap filled with gas. When a particle impinges on
the plates, the ionized charge flows between the dielectric plates
which is subsequently read out by metal plates via capacitive coupling
\cite{atlas-detector}. Figure \ref{fig:rpc-readout} shows the layout
of the RPC readout strips in relation to the dielectric inserted
between the copper grounding plates. The RPCs also provide an
additional measurement in the non-bending $\phi$ direction to
complement the MDT measurement \cite{atlas-detector}.

#+CAPTION: Layout of TGC and RPC chambers at ATLAS used to reconstruct muons \cite{atlas-detector}. 
#+NAME: fig:rpc-tgc-trigger
#+ATTR_LATEX: :width 0.75\linewidth 
[[file:figures/RPC_TGC_schematics.pdf]] 
 
#+CAPTION: Schematic of the RPC readout strips \cite{atlas-detector}. 
#+NAME: fig:rpc-readout
#+ATTR_LATEX: :width 0.75\linewidth 
[[file:figures/RPC_readout_strips_5.pdf]] 
*** Thin Gap Chambers
The TGC serves a similar purpose as the RPCs do. They are the magenta
regions of Figure \ref{fig:rpc-tgc-trigger}. TGCs and RPCs operate
using similar physical processes but differ in the materials used
\cite{atlas-detector}. The region of the TGC filled with gas is 2.8 mm
wide. The gas mixture is CO_2 and n-pentane which results in a lower
gas gain. The anodes are held at a potential of 2.9 kV. The operating
parameters of the TGC allow it to read out signals within 25ns
\cite{atlas-detector}. Figure \ref{fig:tgc-layout} shows a schematic
of a TGC module at ATLAS.
#+CAPTION: Schematic of the TGC layout. G-10 is a glass reinforced epoxy laminate \cite{atlas-detector}. 
#+NAME: fig:tgc-layout
#+ATTR_LATEX: :width 0.75\linewidth 
[[file:figures/TGC_structure.pdf]] 
** Track and Vertex Reconstruction
Track reconstruction at ATLAS relies on a variety of strategies to
determine the best set of track parameters to describe the momentum of
the charged particles passing through the inner detector and muon
spectrometer \cite{Cornelissen:2008zzc}. Broadly speaking, track
reconstruction starts using an "inside-out" approach beginning with
information from the pixel detector, ambiguity resolution of silicon
hit information, extension to the TRT, and finally an "outside-in"
approach beginning from the TRT working backwards
\cite{Cornelissen:2008zzc}. This ensures that processes which leave
tracks in the outer parts of the detector but not in the innermost
silicon layers still get reconstructed. Such processes are long-lived
decays (e.g. $K_s$ decays) or photon conversions (a photon
pair-produces to $e^+e^-$ leaving two tracks in the outer detector
volume) \cite{Cornelissen:2008zzc}. Vertex reconstruction occurs by
iteratively following high quality tracks back to a common point and
assigning these tracks to a primary vertex. A \chi^2 is formed and
remaining tracks that are displaced more than 7\sigma from the primary
vertex are considered for the next iteration of vertex searching. The
process is repeated until no additional vertices can be found
\cite{stanecka:1529765}.

The actual estimation of track parameters is determined using a Kalman
filter \cite{Cornelissen:2008zzc}. The Kalman filter works by
iteratively updating the best estimate of the track parameters based
on the addition of new measurements of the track parameters. It
rapidly converges to the true result in the presence of noise and
uncertainty in the measurement parameters \cite{Fruhwirth:1987fm}.
These properties make it ideally suited for track reconstruction in
the high-occupancy environment of ATLAS.

*** Inside-out sequence
#+CAPTION: Example reconstruction of three tracks *a* *b* and *c*, hits are scored to determine optimal association of hits to each track. \cite{Cornelissen:2008zzc}. 
#+NAME: fig:ambiguity
#+ATTR_LATEX: :width 0.75\linewidth 
[[file:figures/ambiguity_resolution.pdf]] 

The three dimensional information of the silicon hits are used to seed
the track reconstruction. Track seeds are created by applying a window
search through the seed directions which are then fed to a simplified
Kalman filter that creates an initial list of track candidates
\cite{Cornelissen:2008zzc}. Figure \ref{fig:ambiguity} shows three
tracks reconstructed during track seeding. Hits associated to tracks
that lead to better track quality are scored higher than those that do
not. Similarly, poor quality hits are scored lower than high quality
ones. After resolving ambiguous hits the resulting tracks are extended
into the TRT volume. TRT hits which lie along the reconstructed tracks
are associated with each track. The software requires that adding TRT
hits to the track does not modify the tracks extracted by the silicon
hits of the previous steps \cite{Cornelissen:2008zzc}. Figure
\ref{fig:trt-ttbar} shows the TRT extension procedure for a simulated
$t\bar{t}$ event at ATLAS, red TRT hits are associated with the tracks
reconstructed in the silicon layers. After TRT hits are associated to
the tracks, the inside-out sequence is halted.

#+CAPTION: A simulated $t\bar{t}$ event illustrating the TRT extension procedure.  Red TRT hits are associated with tracks represented by red hits in the silicon layers \cite{Cornelissen:2008zzc}. 
#+NAME: fig:trt-ttbar
#+ATTR_LATEX: :width 0.75\linewidth 
[[file:figures/ttbar_trt_extension.pdf]] 
*** Outside-in sequence
There are a number of physical processes which cause tracks which
appear in the TRT to not be reconstructed during the inside-out
reconstruction. These include long-lived decays as well as tracks that
did not survive the ambiguity solving during the inside-out
reconstruction. Hits not associated with tracks are considered in
track finding and the resulting tracks are extended into the silicon
to further associate hits to the tracks. Electrons lose significant
amounts of energy in the TRT which makes the gaussian assumption
underlying the performance of the Kalman filter fail. Different
pattern recognition techniques are used to reconstruct these tracks
with a high efficiency \cite{Cornelissen:2008zzc}.
*** Track Parameters
#+CAPTION: Perigee definition used by ATLAS \cite{Salzburger:1038100}. 
#+NAME: fig:perigee
#+ATTR_LATEX: :width 0.75\linewidth 
[[file:figures/track_perigee.pdf]] 

The track reconstruction algorithm as described does not make any
reference to specific track parameters. The unique magnetic field that
tracks traverse as they leave the detector makes a traditional helix
parameterization difficult, therefore a generic set of parameters is
defined at each measurement surface \cite{Salzburger:1038100}.
#+BEGIN_LaTeX
\begin{equation}
\mathbf{x} = (l_1,l_2,\phi,\theta,q/p)^T
\end{equation}
#+END_LaTeX
These local parameters are converted to the global kinematic
parameters using ATLAS's definition of perigee parameters shown in
Figure \ref{fig:perigee} \cite{Salzburger:1038100}. The azimuthal
angle \phi and the polar angle \theta are measured from the
interaction point. The ratio $q/p$ is measured based on the curvature
of the track in the magnetic field. Figure \ref{fig:atlas-bfield}
shows the magnetic field at ATLAS in the $r-z$ coordinates. The
curvature of the track is determined by estimating the path a track
takes as traverses the field using finite element analysis of the
field \cite{Salzburger:1038100}.

#+CAPTION: The magnetic field at ATLAS in the $r-z$ coordinate plane. The bottom plot shows a zoomed in view of the solenoidal field in the inner detector.  The toroidal field is shown in the upper plot. \cite{Salzburger:1038100}. 
#+NAME: fig:atlas-bfield
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/atlas_bfield.pdf]] 

** Trigger
At the design luminosity at the LHC, there are approximately 10^{18}
interactions per second.  The information describing each event takes
1.8 MB of disk space.  The hardware available at the time of the
construction of the LHC means that only 200 events can be written per
second (ie a bandwidth of 2.6 GB/s) \cite{atlas-detector}. A
sophisticated system of hardware and software algorithms select events
to be saved for further analysis. The entire system is referred to as
the Trigger and Data Acquisition \cite{atlas-detector}. The trigger
system drives the types of analyses that can be done as they are the
first line of selection on the particles produced in collisions.

The trigger is comprised of three levels, each considering more of the
detector information than the last, and each refining the estimates of
the physics objects in the event. The first level, (L1) is implemented
at the hardware level. The L1 uses the RPC and TGC chambers of the
muon spectrometer, and coarse information from the calorimeters for
identification of $\tau$ leptons, electrons, jets, and missing
transverse energy. The L1 accept rate is 75 kHz and the decision must
reach the front end electronics in 2.5 $\mu$s.  The L1 trigger also
creates regions of interest (RoI) which identify locations in
$\eta-\phi$ space for further consideration by the level 2 (L2)
trigger \cite{atlas-detector}.  

The L2 trigger and the event filter (EF) constitute the high level
trigger (HLT). The L2 trigger reduces the event rate to 2.5 kHz. The
L2 trigger inspects the RoIs identified by the L1 trigger. The L2
trigger consists of a processing farm which runs partial event
reconstruction in order to further refine the event rate. The output
of the L2 trigger is passed onto the EF. The EF runs the full atlas
reconstruction software on the event. A final decision is made on the
reconstructed physics objects and are written out to disk
\cite{atlas-detector}. This analysis uses the following trigger chain:
=L1_MU15= $\rightarrow$ =L2_mu36_tight= $\rightarrow$ =EF_mu36_tight=. The
L1 trigger requires a roughly identified muon with $p_T > 15 GeV$. The
L2 and EF triggers require a muon with $p_T > 36 GeV$. There are low
$p_T$ dimuon triggers available for $J/\psi$ reconstruction but they
degrade in efficiency at the high $p_T$ explored by this analysis
\cite{Picazio:1419765}.

#+LaTeX: \chapter{Event Reconstruction and Selection}
#+LaTeX: \label{chap:reconstruction}
* J/\psi reconstruction
In Chapter \ref{chap:theory} the J/\psi particle is understood as a
quarkonium state consisting of a charm and anti-charm quark. After the
pair is produced, it rapidly decays to either hadrons, a pair of
electrons or a pair of muons (see Table \ref{tab:jpsi-decay})
\cite{Agashe:2014kda}. In order to decay to pairs of leptons the
quarks must decay through a virtual photon (electromagnetically). If
the final state is a parton, the pair can decay through a gluon (via
the strong interaction) or a virtual photon. This leads to the
relative size of the electron and muon contribution to the decay
modes.

#+CAPTION: Summary of J/\psi decay modes \cite{Agashe:2014kda}
#+NAME: tab:jpsi-decay
| J/\psi Decay Mode | Fraction           |
|-------------------+--------------------|
| hadrons           | $87.7\pm 0.5$ %    |
| $e^+ e^-$         | $5.971\pm 0.032$ % |
| $\mu^+ \mu^-$     | $5.961\pm 0.033$ % |

While the rate of J/\psi decaying to muons is around 6% of the total
production, it represents a very clean experimental signal.  One of
the major design requirements of ATLAS is the accurate reconstruction
of muons across a wide momentum range.  

Events which contain a high $p_T$ muon are inspected for J/\psi
candidates by checking for additional muons in the event. If there are
two oppositely charged muons in the event, they are considered as a
J/\psi candidate by refitting the tracks to a common vertex. If the
tracks are not already associated with the same vertex, this process
modifies the track momentum slightly to more accurately reflect the
hypothesis that the pair originated as a J/\psi. Figure
\ref{fig:vtx-refit} illustrates this process. When a pair of muons is
identified as a J/\psi candidate, those muons are removed from the
inner detector track collection considered by the Jet reconstruction
algorithm. After event reconstruction, the $J/\psi$ candidate is
required to have $p_T > 45$ GeV, and an absolute rapidity $|y| < 2.0$.
Each muon must be central to the detector with $|\eta| < 2.5$.
Finally, the invariant mass of the dimuon pair is required to be
greater than 2.6 GeV and less than 4 GeV.
#+CAPTION: Illustration of how refitting oppositely charged tracks to a common vertex changes the track.
#+NAME: fig:vtx-refit
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/vtx_refit.pdf]] 

When a meson containing a $b$ quark and a $c$ quark is produced, the
$b$ quark may change flavor to a $c$ quark through the weak force in
the Standard Model. The time it takes to complete this process is
quite long which allows the experimental discrimination of events
containing a $b$ quark. The long lifetime of $b$ flavored mesons means
that the decay vertex is displaced from the primary vertex. By
measuring the distance between the refitted vertex and the primary
vertex of the event, an estimate of the lifetime of the particle can
be made. Events which are displaced are referred to as non-prompt,
while events which are not displaced are referred to as prompt. The
lifetime can be estimated by measuring the displacement vector from
the primary vertex ($\mathbf{L}$) and projecting it on the transverse
momentum vector ($\mathbf{p}_T$). This quantity is referred to as
$L_{xy}$ [fn:: Recall the transverse plane (T) is the $x-y$ plane in
the cartesian coordinates used by ATLAS where the beam line is the $z$
axis.]. Determining the pseudo-proper lifetime is then a matter of
scaling this quantity by the ratio of the mass and transverse momentum
of the particle[fn:: In the high energy limit, the relativistic gamma
factor is proportional to the ratio $p_T/m$]:
#+BEGIN_LaTeX
\begin{align}
L_{xy} &= \frac{\mathbf{L}\cdot\mathbf{p}_T}{p_T} \\
c\tau &= \frac{M_{J/\psi}}{p_T(\mu\mu)}L_{xy}
\end{align}
#+END_LaTeX
Figure \ref{fig:pseudo-lifetime} shows the geometric definition of
these quantities.  

The lifetime distribution breaks down as follows:
- A large fraction of signal events will be centered around $c\tau=0$
- A small fraction of events will contribute to a non-coherent
  component with an exponential decay positive and negative in $c\tau$
- A large fraction of background events will follow an exponential
  decay with lifetime equal to the geometric mean of the $B$ hadron
  lifetimes that contribute to the overall background.  

It is possible that two oppositely charged muons are produced near
enough to each other that they are refit as a $J/\psi$ candidate
without originating from a $c\bar{c}$ pair. Since these events come
from the wrong combination of muons, they are referred to as the
combinatoric background. The invariant mass of these muon pairs does
not produce a resonance near the mass of the $J/\psi$ the way muons
from $J/\psi$ decays do. This makes the invariant mass $M_{\mu\mu}$
the variable which discriminates true $J/\psi$ candidates from the
wrong combination of muons.

#+CAPTION: The definition of the pseudo-proper lifetime is derived from the signed projection of the distance between the primary vertex and the secondary vertex.
#+NAME: fig:pseudo-lifetime
#+ATTR_LATEX: :width 0.75\linewidth 
[[file:figures/pseudo_lifetime_def.pdf]] 
 
* Jet definitions
In Chapter \ref{chap:theory} the discussion of jets ended with the
hadronization of partons to be reconstructed by the detector. This
section describes how the detector level objects are grouped together
to form candidates which represent the originating parton in those
interactions. When a single hard parton showers and subsequently
hadronizes, the QCD radiation emitted is typically collinear with the
parton. This results in hadrons which are collimated in the detector.

A rigorous jet definition simultaneously captures the momentum of the
parton before the parton shower and has a well defined prescription
for associating detector level objects to the jet \cite{Salam:2009jx}.
Two critical properties of such an algorithm are infrared safety and
collinear safety. Infrared safety means that adding soft (low
momentum) radiation to the event doesn't change the reconstructed
jets, this is illustrated in Figure \ref{fig:infrared-safe}. Collinear
safety means that if a single hard particle is split into a collinear
pair, the reconstructed jets remain the same as illustrated in Figure
\ref{fig:collinear-safe} \cite{Salam:2009jx}.


#+CAPTION: Collinear safety means splitting one hard momentum vector into two does not change the jets reconstructed by the algorithm.
#+NAME: fig:collinear-safe
#+ATTR_LATEX: :width 0.75\linewidth 
[[file:figures/collinear_safe.pdf]] 

#+CAPTION: Infrared safety means adding a soft particle to the list of particles does not change the jets reconstructed by the algorithm.
#+NAME: fig:infrared-safe
#+ATTR_LATEX: :width 0.75\linewidth 
[[file:figures/infrared_safe.pdf]] 
** Jet Reconstruction
There are many reconstruction algorithms that satisfy the conditions
outlined above.  The algorithm used in this work is the anti-$k_t$
algorithm, a sequential recombination algorithm widely used in modern
high energy physics experiments. Sequential recombination algorithms
operate in the following steps:
1. A list of pseudo-jet's momentum are provided as input (on the first step this
   is a list of reconstructed particle's momentum)
2. For each pseudo-jet $i$ a quantity $d_{ij}$ and $d_{iB}$ is
   calculated where $d_{ij}$ is a distance measure between the
   pseudo-jet $i$ and another pseudo-jet $j$.  The quantity $d_{iB}$
   is the distance between the pseudo-jet and the beam.
3. The minimum of $d_{ij}$ and d_{iB} is determined.  If $d_{ij}$ is
   smaller, the two momentum $i$ and $j$ are combined to form a new
   pseudo-jet.  If $d_{iB}$ is smaller, this pseudo-jet is considered
   as a jet and removed from the list of pseudo-jets
4. Steps 1-3 are repeated until no pseudo-jets remain.

In the anti-$k_t$ algorithm the distance measure is defined as:
#+BEGIN_LaTeX
\begin{align}
 d_{ij} &= \min(k_{ti}^{-2},k_{tj}^{-2})\frac{\Delta_{ij}^2}{R^2} \\
 d_{iB} &= k^{-2}_{ti}
\end{align}
#+END_LaTeX
Here $\Delta_{ij}^2 = (y_i-y_j)^2 + (\phi_i - \phi_j)^2$, $k_t$,
$\phi$, and $y$ being the transverse momentum, azimuthal angle and
rapidity of the pseudo-jet four vector respectively
\cite{1126-6708-2008-04-063}. The parameter $R$ is the predetermined
radius of the jets. For this work $R=0.4$ is used. Anti-$k_t$ produces
circular jets as opposed to other sequential recombination algorithms.
Figure \ref{fig:anti-kt} shows the anti-$k_t$ clustering for a
three-jet event. 
#+CAPTION: Illustration of the anti-$k_t$ algorithm.  Each step clusters a new particle until a jet is formed and clustering continues until no pseudo-jets remain. 
#+NAME: fig:anti-kt
#+ATTR_LATEX: :width 1.0\linewidth 
[[file:figures/antikt_algorithm.pdf]] 

Jets in this analysis are reconstructed with the anti-$k_t$ clustering
scheme using inner detector tracks as the pseudo-jets. In order to
correctly capture the dynamics of the radiation environment around the
$J/\psi$, the muons associated with the reconstructed $J/\psi$ are
removed from list of tracks considered for jet reconstruction. In
place of these tracks, the $J/\psi$ four vector is added. This
provides as accurate a representation of the charmonium and the
embedded radiation as possible. The tracks considered in
reconstruction must be high quality. In order to achieve this, they
must have a minimum $p_T$ of 500 MeV, a maximum absolute
pseudo-rapidity, $|\eta| < 2.5$, at least one hit in the pixel
detector and 6 SCT hits. Finally the fit $\chi^2$ must be at most 3.
Impact parameter cuts (see Figure \ref{fig:perigee}) $z_0\sin(\theta)
< 1.5$ and $d_0 < 1.0$ are also applied. The final set of jets that
are reconstructed must be central to the detector $|\eta| < 2.5$ and
must have high transverse momentum $p_T > 45$ GeV. Finally, the
$J/\psi$ and the jet must be within $\Delta R < 0.4$ (the
reconstructed jet radius).

* Observables
At this point it is useful to introduce the observables used in this
analysis. There are two: $z$ and $\Delta R$. The first, $z$ is the
momentum fraction shared between the $J/\psi$ and the reconstructed
jet. The momentum fraction is defined as:
#+BEGIN_LaTeX
\begin{equation}
z = \frac{p_T(J/\psi)}{p_T(\text{Jet})}
\end{equation}
#+END_LaTeX
As a reminder, the jet is clustered to include the $J/\psi$
four-vector.  As a result, the momentum fraction exists in $0 < z \leq
1$.  This fraction directly probes the final splitting in the parton
shower into the $c\bar{c}$ bound state that becomes the $J/\psi$
relative to the energy scale of the initial interaction.  A value
around $z=0.5$ indicates that the $p_T$ of the $J/\psi$ and the p_T of
the surrounding radiation are equal.  A value of $z\simeq1$ indicate that
all the momentum is carried by the $J/\psi$ and very little in
surrounding radiation.  Similarly a $z$ value near zero indicates all
the is momentum carried in the radiation within an $R=0.4$ cone of the
reconstructed $J/\psi$[fn:: This is very unlikely to happen due to the
high $p_T$ requirement of the $J/\psi$].  

The second variable examined by this analysis is the angular
separation between the $J/\psi$ and the reconstructed jet.  This
quantity, denoted $\Delta R$ is defined as:
#+BEGIN_LaTeX
\begin{equation}
\Delta R = \sqrt{\Delta \phi^2 + \Delta \eta^2}
\end{equation}
#+END_LaTeX
If the radiation emitted around the $J/\psi$ is isotropic in
$\phi-\eta$, then the $\Delta R$ between the $J/\psi$ and the
reconstructed jet should be $\Delta R=0$. The more the production of
the $c\bar{c}$ system depends on the fragmentation of partons, the
more likely the $\Delta R$ measurement will be peaked away from
$\Delta R=0$. Put another way, no radiation activity around the
$J/\psi$ will correspond to $\Delta R=0$, a large amount of radiation
around the $J/\psi$ increases the chance that a hard emission changes
the alignment of the $J/\psi$ to the surrounding radiation. Figure
\ref{fig:prod-mech} shows Pythia's prediction of $z$ and $\Delta R$
for the singlet and octet components available for simulation
\cite{Sjostrand:2007gs}.
#+BEGIN_LaTeX
  \begin{figure}
    \centering
    \subfloat[$z$]{
      \label{fig:jet_z-prod-mech}
      \includegraphics[width=0.45\textwidth]{plots/mech/jet_z.pdf}
    }\qquad
    \subfloat[$\Delta R$]{
      \label{fig:delta_r-prod-mech}
      \includegraphics[width=0.45\textwidth]{plots/mech/delta_r.pdf}
    } \caption{\label{fig:prod-mech} Pythia 8 prediction of each
    production mechanism for $z$ and $\Delta R$ observables. The lower
    panel shows the ratio of each sample to the $^1S_0^{(8)}$ process in
    order to show the similarity between the other octet processes and
    the difference between the singlet processes. }
  \end{figure}
#+END_LaTeX


#+LaTeX: \chapter{Analysis Methods}
#+LaTeX: \label{chap:analysis}
* Likelihood Formalism
The maximum likelihood (ML) fit method is a statistical method for
estimating parameters which describe the probability density function
(PDF)[fn:: This section follows the notation in \cite{James:2006zz}
which differs slightly from the notation used in literature.]. The PDF
can be motivated by physical first principles or empirically. The
likelihood function is defined as the probability of a set of
parameters given observed data. Maximizing the likelihood function
with respect to these parameters provides a best estimate of the
parameters. The likelihood function is constructed as a product over
probability functions for observing a random variable $x$
\cite{Barlow:1990vc}:
#+BEGIN_LaTeX
\begin{equation}
\mathcal{L} = \prod_{i=1}^N p(x_i | \bm{\theta})
\end{equation}
#+END_LaTeX
Here $N$ is the number of observed events and $\bm{\theta}$ is a
vector of parameters which describe the PDF[fn:: For example, in the
function of a line $p(x| m, b)=mx+b$, the slope ($m$) and intercept of
a line ($b$) are parameters of the variable $x$.]. It is important to
note that the parameters $\theta_i$ do not represent a conditional
probability. Instead, they are parameters of a function describing the
PDF, independent of the random variable observed ($x_i$). Each
probability function $p(x| \bm{\theta})$ is normalized
\cite{Barlow:1990vc}:
#+BEGIN_LaTeX
\begin{equation}
\int p(x|\bm{\theta}) = 1
\end{equation}
#+END_LaTeX
Rather than maximizing the likelihood directly, it is easier to
maximize (minimize) the (negative) logarithm of the likelihood:
#+BEGIN_LaTeX
\begin{equation}
\label{eq:nll}
- \log \mathcal{L} = - \sum_{i=1}^{N} \log(p(x_i|\bm{\theta}))
\end{equation}
#+END_LaTeX
Equation \ref{eq:nll} is minimized over the parameters $\theta_j$. The
value of these parameters represent the estimation of the PDF that
most likely describes the observed data, hence the name "maximum
likelihood fit." The computational framework that allows the use of
the ML fit is RooFit, a general purpose statistical tool for
performing and evaluating fits to data \cite{Verkerke:2003ir}. The
algorithm used by RooFit to perform the minimization is a gradient
descent called Minuit \cite{James:2004xla}.

** Extracting the Signal
The likelihood method provides a powerful tool for assessing the
likelihood that a particular event is signal or background depending
on the parameters extracted from the fit. The technique used for this
purpose is called sPlot \cite{Pivk:2004ty}. This method utilizes
properties of the extended likelihood formalism to derive a set of
weights representing categories parametrized by the PDFs used in the
ML fit. SPlot requires that the normalization condition be relaxed
such that for a given component of the likelihood function
\cite{Barlow:1990vc}:
#+BEGIN_LaTeX
\begin{equation}
\int P(x|\bm{\theta}) dx = N(\bm{\theta})
\end{equation}
#+END_LaTeX
This allows the re-expression of the negative log-likelihood function as \cite{Pivk:2004ty}:
#+BEGIN_LaTeX
\begin{equation}
\label{eq:enll}
- \log \mathcal{L} = - \sum_{i=1}^{N} \log(\sum_{j=1}^{\mathcal{N}_s} N_j p_j(x_i|\bm{\theta}))
\end{equation}
#+END_LaTeX
In this expression $\mathcal{N}_{s}$ is the number of species (in this
case, signal or background) to be separated, $N_j$ is the number of
the $j^{\text{th}}$ species and $p_j$ is the PDF describing the
$j^{\text{th}}$ species. SPlot also requires knowledge of the
covariance matrix. This is can be estimated from the likelihood
function by \cite{Pivk:2004ty}:
#+BEGIN_LaTeX
\begin{equation}
\label{eq:v-inverse}
V^{-1}(\hat{\bm{\theta}})_{ij} = \frac{\partial^2(-\mathcal{L}(x|\bm{\theta}_0))}{\partial N_i\partial N_j}
\end{equation}
#+END_LaTeX
Here $\bm{\theta}_0$ are the parameters estimated from the ML fit.
With these ingredients it is possible to derive the weights required
to reconstruct a histogram of the estimated signal. The expression
obtained is:
#+BEGIN_LaTeX
\begin{equation}
W_S(x) = \frac{\sum_{j=1}^{N_s} V_{Sj}p_j(x)}{\sum_{k=1}^{N_s} N_k p_k(x)}
\end{equation}
#+END_LaTeX
The matrix $V_{Sj}$ is obtained from the likelihood function by
numerically inverting Eq. \ref{eq:v-inverse}.  It is informative to
expand this expression for the case of two species, signal and
background as used in this analysis. For the case of signal the
weight is:
#+BEGIN_LaTeX
\begin{equation}
W_S(x) = \frac{V_{SS} p_S(x) + V_{SB} p_B(x)}{N_Sp_S(x)+N_Bp_B(x)}
\end{equation}
#+END_LaTeX
In this expression it is clear that the weight depends on the PDF for
the signal and background and is weighted by the covariance of these
two components.  In the extreme case where signal and background are
perfectly separated the covariance matrix is diagonal and the weight
reduces to:
#+BEGIN_LaTeX
\begin{equation}
W_S(x) = \frac{\sigma_S p_S(x)}{N_Sp_S(x)+N_Bp_B(x)}
\end{equation}
#+END_LaTeX
Where $\sigma_S$ is the variance of the signal PDF. This weight is
applied per event and on average it reproduces the signal histogram.
* Empirical Model
In Section [[J/\psi reconstruction]] the two sources of background were
introduced: non-prompt decays from $B$ hadrons distinguished by the
$c\tau$ distribution and combinatoric events from the wrong pair of
muons distinguished by the invariant mass of the di-muon pair
$M_{\mu\mu}$. The fit to the data is parameterized by a joint PDF in
$M_{\mu\mu}$ and $c\tau$. The specific parameterization has been used
previously to extract J/\psi events \cite{ATLAS-CONF-2015-024}. It is
defined as:
#+BEGIN_LaTeX
\begin{equation}
PDF(m,t) = \sum_{i} f_{i}(m)\cdot h_{i}(t)\otimes g(t)
\label{eq:pdf}
\end{equation}
#+END_LaTeX
Here $\otimes$ is convolution while $\cdot$ is PDF multiplication. In
the following $\oplus$ refers to a weighted sum of two PDF components
such that the result remains properly normalized. The individual fit
components are listed in Table \ref{tab:fit-comps}. The function
$g(t)$ is resolution function of the lifetime distribution. It is a
double-gaussian and is convolved with each lifetime component.
#+CAPTION: Individual components of simultaneous fit to data. 
#+CAPTION: Functions are notated as follows: $\delta(x)$, the dirac delta
#+CAPTION: function; $CB_{k}(x)$, the \emph{k}th Crystal Ball function;
#+CAPTION: $G_{k}(x)$ a Gaussian function; $E_{k}(x)$, the \emph{k}th exponential
#+CAPTION: decay; $P^{n}(x)$ a polynomial of degree $n$. A function with the same
#+CAPTION: $k$ index shares the same free parameters.
#+LABEL: tab:fit-comps
| $i$ | Source                  | $f_{i}(m)$                 | $h_{i}(t)$            |
|-----+-------------------------+----------------------------+-----------------------|
|   1 | Prompt $J/\psi$         | $CB_{1}(m)\oplus G_{1}(m)$ | $\delta(t)$           |
|   2 | Non-prompt $J/\psi$     | $CB_{1}(m)\oplus G_{1}(m)$ | $E_{1}(t)$            |
|   3 | Prompt Background       | $P^{0}(m)$                 | $\delta(t)$           |
|   4 | Non-prompt Background   | $P^{1}(m)$                 | $E_{2}(t)$            |
|   5 | Non-coherent Background | $E_{3}(m)$                 | $E_{4}(\vert t\vert)$ |
|-----+-------------------------+----------------------------+-----------------------|
The choice of these specific functions and the components they model
deserve explanation. The constructed PDF is a joint PDF in
$M_{\mu\mu}$ (denoted $m$ in the fit) and $c\tau$ (denoted $t$ in the
fit). This means that each component must have a mass component and a
lifetime component. The shape used for the $J/\psi$ resonance in $m$
is the sum of a Gaussian and a Crystal Ball function.  The Crystal
Ball has the shape of Gaussian, but is asymmetric and allows the
correct modeling of losses that give the resonance a low mass tail.
The function is defined as:
#+BEGIN_LaTeX
\begin{align}
\label{eq:crystal-ball}
f(m;\alpha,n,\mu,\sigma) &= N \cdot 
\begin{cases}
\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right) & \text{for}~\frac{x-\mu}{\sigma} > -\alpha \\
A \cdot\left(B-\frac{x-\mu}{\sigma}\right)^{-n} & \text{for}~\frac{x-\mu}{\sigma} \leq -\alpha
\end{cases}\\
A &= \left(\frac{n}{|\alpha|}\right)^n \exp\left(-\frac{|\alpha|^2}{2}\right)\\
B &= \frac{n}{|\alpha|} - |\alpha|
\end{align}
#+END_LaTeX
Here $N$ is the normalization factor, $\mu$ is the mean and $\sigma$
the width of the Gaussian portion. The parameters $n=1$ and
$\alpha=10$ are fixed in the fit but varied in separate fits to assess
their impact on the systematic uncertainty.

The signal component is defined as the prompt $J/\psi$ component; the
remainder is background. The non-prompt component shares the same mass
signal PDF, but has an exponential distribution in $t$. The remaining
components of the PDF do not contribute to the estimate of real
$J/\psi$ events. The portion of events which appear prompt but are
from the wrong combination of muons, a constant function in mass and a
delta function in $t$ are used. There is a portion of events which
appear to have a negative lifetime depending on the measurement of
$L_{xy}$. This component is modeled as a double-sided exponential in
$t$ and an exponential in $m$. The combinatoric background component
is linear in $m$ and exponential in $t$. Including fractions which
float to ensure the PDF is normalized, the fit includes fourteen free
parameters.

Figure \ref{fig:fit-res-m} and Figure \ref{fig:fit-res-lt} shows the
result of the simultaneous fit to the 2012 data set for the dimuon
invariant mass distribution and pseudo-proper lifetime distribution
respectively. Selected fitted values of the PDF are summarized in
Table \ref{tab:fitres}.
#+BEGIN_LaTeX
    \begin{figure}
      \centering
      \subfloat[$M_{\mu\mu}$ fit result]{
        \label{fig:fit-res-m}
        \includegraphics[width=0.5\textwidth]{plots/mass_fit_final.pdf}
      }
      \subfloat[$c\tau$ fit result]{
        \label{fig:fit-res-lt}
        \includegraphics[width=0.5\textwidth]{plots/tau_fit_final.pdf}
      } \caption{\label{fig:fitres} Result of unbinned likelihood fit to
  invariant mass distribution of dimuon pairs in data and pseudo-proper
  lifetime distribution. See \ref{tab:fit-comps} for a list of the fit
  components.}
    \end{figure}
#+END_LaTeX

#+CAPTION: Summary of fit to dataset with nominal parameterization, Estimated Distance to Minimum: 0.84577\times 10^{-3}. 
#+LABEL: tab:fitres
| Parameter Name          | Fitted Value                       |
|-------------------------+------------------------------------|
| $J/\psi$ Mass           | 3.0969 \pm 0.0002 GeV              |
| $J/\psi$ Width          | (0.82 \pm 0.01)\times 10^{-1} GeV  |
| Lifetime                | 0.313 \pm 0.001 mm                 |
| Non-coherent Lifetime   | 0.161 \pm 0.003 mm                 |
| Non-prompt Lifetime     | 0.344 \pm 0.002 mm                 |
| Resolution Width        | (0.109 \pm 0.001)\times 10^{-1} mm |
| Second Resolution Width | (0.308 \pm 0.005)\times 10^{-1} mm |
| Non-Coherent Mass c_{1} | -0.2640 \pm 0.0004      1/GeV      |
|-------------------------+------------------------------------|
** Validating signal extraction
A fundamental assumption of sPlot is that the variable of interest
($\Delta R$ and $z$) is uncorrelated with the discriminating variables
($c\tau$ and $M_{\mu\mu}$). The 2D histograms of the interest
variables versus the discriminating variables and their global
correlation is shown in Figure \ref{fig:delta_r-splot-corr} and
\ref{fig:jet_z-splot-corr}.
#+BEGIN_LaTeX
  \begin{figure}
    \centering
    \subfloat[$\Delta R$ vs lifetime]{
      \label{fig:delta_r-tau-splot-corr}
      \includegraphics[width=0.45\textwidth]{plots/correlation/delta_r_tau_corr.pdf}
    }
    \subfloat[$\Delta R$ vs $M_{\mu\mu}$]{
      \label{fig:delta_r-m-splot-corr}
      \includegraphics[width=0.45\textwidth]{plots/correlation/delta_r_m_corr.pdf}
    } 
    \caption{\label{fig:delta_r-splot-corr} Two-dimensional histogram of
    $\Delta R$ vs discriminating variables used to extract background
    component from sPlot method}
  \end{figure}
#+END_LaTeX

#+BEGIN_LaTeX
  \begin{figure}
    \centering
    \subfloat[Jet $z$ vs lifetime]{
      \label{fig:jet_z-tau-splot-corr}
      \includegraphics[width=0.45\textwidth]{plots/correlation/jet_z_tau_corr.pdf}
    }
    \subfloat[Jet $z$ vs $M_{\mu\mu}$]{
      \label{fig:jet_z-m-splot-corr}
      \includegraphics[width=0.45\textwidth]{plots/correlation/jet_z_m_corr.pdf}
    }
    \caption{\label{fig:jet_z-splot-corr} Two-dimensional histogram of
    Jet $z$ vs discriminating variables used to extract background
    component from sPlot method}
  \end{figure}
#+END_LaTeX

In order to ensure the background extraction procedure is correctly
estimating the shape, sideband regions are defined and compared to the
sPlot estimate. Sideband regions are intervals of $c\tau$ and
$M_{\mu\mu}$ where the background is expected to dominate the
distribution. If these shapes roughly agree, then there is confidence
that sPlot is correctly estimating the shape in the signal region. The
non-prompt background region is defined as $3 \sigma_{c\tau} < ct <$
50 mm where $\sigma_{c\tau}$ is determined from the simultaneous fit.
The combinatoric background region is defined as more than $3\sigma_m$
where $\sigma_m$ is the width of the fitted mass peak. Figure
\ref{fig:splot-bkg} shows the result of this comparison.
#+BEGIN_LaTeX
    \begin{figure}
      \centering
      \subfloat[$z$]{
        \label{fig:jet_z-splot-bkg}
        \includegraphics[width=0.45\textwidth]{plots/jet_z_splot_bkg.pdf}
      }\qquad
      \subfloat[$\Delta R$]{
        \label{fig:delta_r-splot-bkg}
        \includegraphics[width=0.45\textwidth]{plots/delta_r_splot_bkg.pdf}
      } \caption{\label{fig:splot-bkg} Background extracted from the
      sPlot method compared to the sideband regions for the jet momentum
      fraction $z$ and the $J/\psi$ jet separation $\Delta R$}
  \end{figure}
#+END_LaTeX

While this gives confidence that the background shape is estimated
properly, it is useful to compare the signal shape of the transverse
momentum distribution to ensure that the Monte Carlo is correctly
modeling this shape. The comparison of the reconstructed Jet $p_T$ and
$J/\psi$ $p_T$ are shown in Figures \ref{fig:jet_pt-sbs-p8} and
\ref{fig:jpsi_pt-sbs-p8}. In addition, Figure \ref{fig:jet_pt-splot}
and \ref{fig:jpsi_pt-splot} show the sPlot estimations of the signal
and background. It is expected that the non-prompt fraction increases
with the $J/\psi\text{'s}$ $p_T$ \cite{ATLAS-CONF-2015-024} which is
observed in Figure \ref{fig:jpsi_pt-splot}.

#+BEGIN_LaTeX
  \begin{figure}
    \centering
    \subfloat[Data vs Pythia Jet $p_T$]{
      \label{fig:jet_pt-sbs-p8}
      \includegraphics[width=0.45\textwidth]{plots/jet_pt_sbs_p8.pdf}
    }
    \subfloat[Signal and Background, Jet $p_T$]{
      \label{fig:jet_pt-splot}
      \includegraphics[width=0.45\textwidth]{plots/jet_pt_splot.pdf}
    }\\
     \subfloat[$J/\psi$ $p_T$]{
      \label{fig:jpsi_pt-sbs-p8}
      \includegraphics[width=0.45\textwidth]{plots/jpsi_pt_sbs_p8.pdf}
    }
    \subfloat[Signal and Background $J/\psi$ $p_T$]{
      \label{fig:jpsi_pt-splot}
      \includegraphics[width=0.45\textwidth]{plots/jpsi_pt_splot.pdf}
    } 
    
    \caption{\label{fig:pt-comp} Transverse momentum distributions of
    the $J/\psi$ and matched jet compared to the Pythia prediction (red
    for singlet, blue for octet, left panel). Signal (orange) and
    background (green) compared to data (right panel). }
  \end{figure}
#+END_LaTeX

* Unfolding
Implicit in the measurement of any quantity is the uncertainty
associated with the measurement. There are systematic effects which
may distort the true value of the quantity measured. The size of these
effects is estimated through the assessment of systematic errors by
varying the input and taking the difference from the nominal result.
The finite resolution of the will distort the measured value relative
to the true value in a random but consistent way \cite{Cowan:1998ji}.
It is the goal of unfolding to remove these types of effects. This
problem goes under different names in different fields such as
deconvolution or unsmearing \cite{Cowan:1998ji}.

In the case of a perfect detector, the number of events observed in a
particular bin of a histogram will be given by a continuous
probability distribution \cite{Cowan:1998ji}:
#+BEGIN_LaTeX
\begin{equation}
\label{eq:truth-hist}
T_{i} = N \int_{x\in \text{bin}(i)} f(x) dx
\end{equation}
#+END_LaTeX
Here $T$ is referred to as the truth histogram and $f(x)$ as the true
probability distribution function. The factor $N$ is the number of
events observed in a particular experiment. The function
$\text{bin}(i)$ is a function which gives the interval in $x$ for the
given bin $i$. In reality the detector is not perfect, and the
measurement will be distorted. If an event happens, but is not
detected it is termed that the efficiency of detection is less than
one. This efficiency may vary with the observable, and so it is
assigned a function $\epsilon(x)$. In this form the efficiency
represents the probability of detection. Incorporating the efficiency
is a matter of multiplying the probability an event occurs by the
probability of detecting it \cite{Cowan:1998ji}:
#+BEGIN_LaTeX
\begin{equation}
H_{i} = N \int_{x\in \text{bin}(i)} \epsilon(x)f(x) dx
\end{equation}
#+END_LaTeX
The label $H$ is used to refer to what is actually observed as a
result of an experiment with an efficiency. One final possibility
remains: an event has a true value $x$ and the detector measures its
value to be $y$. This can be cast in terms of conditional probability
as $P(y|x)$, which is read as "the probability of observing $y$ given
the true value was $x$." The observed histogram becomes
\cite{Cowan:1998ji}:
#+BEGIN_LaTeX
\begin{equation}
\label{eq:hist-obs}
H_{i} = N \int_{y\in \text{bin}(i)} \int P(y|x)\epsilon(x)f(x) dx dy
\end{equation}
#+END_LaTeX
Note here the slight change in integration: the number of events
observed in the $i^{\text{th}}$ bin is given by the integral over all
possible truth values multiplied by the probability to detect them,
and the conditional probability that they are miss-measured with a
value $y$.

It is useful to combine the detection efficiency and the probability
the detector changes a measurement from its true value in one
function, the response function \cite{Cowan:1998ji}:
#+BEGIN_LaTeX
\begin{equation}
r(y|x) = P(y|x)\epsilon(x)
\end{equation}
#+END_LaTeX
In practice the integral over $x$ in \ref{eq:hist-obs} is a sum over
the bins in a truth histogram obtained from Monte Carlo simulations of
the detector. In this case it is useful to consider the discrete case
by applying the same method to determine the truth histogram as in
\ref{eq:truth-hist}:
#+BEGIN_LaTeX
\begin{align}
H_i &= \sum_{j=1}^M\frac{\int_{x\in \text{bin}(i)}\int_{y\in \text{bin}(j)}r(y|x)f(x)dydx}{T_j/N}T_j\\
&= \sum_{j=1}^M R_{ij} T_j\\
R_{ij} &= \frac{\int_{x\in \text{bin}(i)}\int_{y\in \text{bin}(j)}r(y|x)f(x)dydx}{T_j/N}
\label{eq:response-def}
\end{align}
#+END_LaTeX
The response[fn:: The name response is given in the sense of how the
detector "responds" to a given truth input] matrix $R_{ij}$ is the
conditional probability of observing an event in bin $i$ given the
true value was in bin $j$. When a true value is modified by the
response function, it is "folded" to give the expected result of the
experiment. The inverse process of determining the true value given
the result of the experiment is referred to as "unfolding."

With the response matrix in hand, it is tempting to invert it and
obtain a direct estimate of the truth:
#+BEGIN_LaTeX
\begin{align*}
H_i &= R_{ij} T_j\\
T_i &= R^{-1}_{ij} H_j
\end{align*}
#+END_LaTeX
The issue with this approach lies in the fact that the response matrix
is estimated from Monte Carlo simulation and applied to the result of
a measurement.  The result of the measurement are subject to
statistical fluctuations independent of those given in the estimate of
the response.  When the inverse response matrix is applied, these
fluctuations are enhanced and overwhelm any physically meaningful
shape that is recovered from the inversion \cite{Cowan:1998ji}.  

It is the goal of any unfolding method to estimate the inverse of
$R_{ij}$ in a way that regularizes the fluctuations in the estimate of
the truth caused by the statistical fluctuations in the experimental
measurement.  Bayes' theorem provides one way of performing an
iterative procedure that allows an estimate of the truth distribution
before the fluctuations grow too large to make conclusions useless. 
** Iterative Bayesian Unfolding
Bayes' theorem provides a way of "inverting" the conditions for a
conditional probability. Using the notation above and assuming
$\epsilon(y)\equiv 1$ \cite{Armbruster:1694351}[fn:: This section
follows the steps in \cite{Armbruster:1694351} which is internal to
ATLAS. The references therein are included here as well to allow
access to the primary sources without access to the internal
document.]:
#+BEGIN_LaTeX
\begin{align}
\label{eq:bayes}
P(x|y) &= \frac{P(y|x)f(x)}{\int f(x) p(y|x) dx} = \frac{P(y|x)f(x)}{g(y)}\\
g(y) &= \int f(x) p(y|x) dx
\end{align}
#+END_LaTeX
Here the correspondence that $x$ is the true value and $y$ is the
measured value is made more explicit.  This allows $f(y)$, the true
distribution to be estimated as:
#+BEGIN_LaTeX
\begin{equation}
f(x) = \int g(y) P(x|y) dx
\end{equation}
#+END_LaTeX
The issue is that in plugging Eq. \ref{eq:bayes} into this definition
of $f(x)$, shows the explicit dependence of $P(x|y)$ on $f(x)$. The
way forward is to determine a first estimate of $f(x)$ and iteratively
update it based on the estimate of $P(y|x)$ from simulations. If one
starts after $k+1$ steps, the following can be written by iteratively
applying Bayes' theorem:
#+BEGIN_LaTeX
\begin{equation}
f^{k+1}(x) = \int f^k(x)\frac{g_{\text{exp}}(y)}{g^k(y)}P(y|x)dy
\end{equation}
#+END_LaTeX
Here $g_{\text{exp}}(y)$ is the distribution obtained by the
experiment.  The denominator, $g^k(y)$, is the result of folding the
$k^{\text{th}}$ estimate of $f(x)$ with the response function
$P(y|x)$.  On each successive iteration, $g^k(y)$ will approach
$g_{\text{exp}}(y)$ as long as $f^k(x)$ approaches the true value
$f(x)$.  

The procedure can be stopped according to different criteria. In the
case of this analysis, the number of iterations is determined ahead of
time by unfolding a known truth distribution that has been folded with
the estimated response matrix. When the value of Pearson's $\chi^2$
between successive iterations reaches a minimum, the procedure is
halted and that number of iterations is used to unfold the data.
*** Estimating the Response Matrix
The response matrix is estimated from the truth information contained
in Monte Carlo simulations of the signal process. For the purposes of
estimating the detector's response to the signal process, all
sub-processes are considered as signal (no distinction is made between
singlet or octet in estimating the matrix). For a given set of events
that pass the selection criteria at the detector level, a plot is made
of the measured value by the simulated detector (referred to as
"reconstructed"), and the value that was generated by the particles
that were input to the detector simulation (referred to as "truth").
The result is a two dimensional histogram whose axes range across the
physical range of the variable. The ordered pair
(truth,recoonstructed) are plotted and the histogram bin these values
fall into are accumulated. The resulting distribution is an estimate
of the response matrix as defined in Equation \ref{eq:response-def}.
In the limit of infinite simulated events, this histogram will
converge to the PDF in equation \ref{eq:response-def}.

*** Validating the Method
The crux of unfolding is to estimate an unknown truth distribution as
accurately as possible using the incomplete description provided by
the detector. In order to have confidence in the results, it is
important to assess the method using controlled inputs. This is
achieved by using a known truth distribution (a single gaussian
centered at the physical range) and folding it with the estimated
response matrix to create a pseudo-reconstructed distribution. The
unfolding procedure is applied to the pseudo-reconstructed
distribution and it is compared to the truth distribution. If the
truth distribution falls outside the physical range of the response
matrix it is truncated. Therefore, the range of validity of the
unfolded pseudo-reconstructed distribution is the physical range
covered by the response matrix. Figures \ref{fig:uc-gaus-jet_z} and
\ref{fig:uc-gaus-delta_r} shows the estimated response matrix and
the unfolding validation test for the $z$ and $\Delta R$ distributions
respectively.
#+CAPTION: Double gaussian unfolding test of $\Delta R$ response matrix
#+NAME: fig:uc-gaus-delta_r
#+ATTR_LATEX: :width 1.0\linewidth
[[file:plots/uc_delta_r_gauss_truth.pdf]]
#+CAPTION: Double gaussian unfolding test of $z$ response matrix
#+NAME: fig:uc-gaus-jet_z
#+ATTR_LATEX: :width 1.0\linewidth
[[file:plots/uc_jet_z_gauss_truth.pdf]]

#+LaTeX: \chapter{Measurement of prompt J/$\psi$ particles}
#+LaTeX: \label{chap:measurement}
* Data sets
Monte Carlo samples are used to: validate the fit to data, estimate
the response matrix, and derive the systematic errors for comparing to
data. The samples used to model the signal and non-prompt background
sources are listed in Table \ref{tab:monte-carlo}.
#+CAPTION: Monte Carlo samples used and their simulated cross section. Each $c\bar{c}$ sample consists of 10^5 events. 
#+LABEL: tab:monte-carlo
| Process                                     |  Cross Section [fb] |
|---------------------------------------------+---------------------|
| $c\bar{c}(^3S_{1}^{(8)})\rightarrow J/\psi$ |                8260 |
| $c\bar{c}(^3P_J^{(1)})\rightarrow J/\psi$   |                 587 |
| $c\bar{c}(^3P_J^{(8)})\rightarrow J/\psi$   |                15.6 |
| $c\bar{c}(^1S_0^{(8)})\rightarrow J/\psi$   |                12.5 |
| $c\bar{c}(^3S_{1}^{(1)})\rightarrow J/\psi$ |               0.307 |
|---------------------------------------------+---------------------|

Data is collected at the LHC in units called periods. Each period is
given an alphabetic designation. During the 2012 data taking there
were ten distinct periods which amounted to a combined luminosity of
$19.5\pm0.6~\text{fb}^{-1}$. The luminosity for each data period is
summarized in Table \ref{tab:data-sets}.
#+CAPTION: Dataset periods during 2012 data taking used in this analysis and their processed Luminosity
#+LABEL: tab:data-sets
| Period | Luminosity (pb^{-1}) |
|--------+----------------------|
| A      |              707.237 |
| B      |              5000.60 |
| C      |              1220.05 |
| D      |              3219.76 |
| E      |              2355.36 |
| G      |              1278.50 |
| H      |              1378.68 |
| I      |              1012.50 |
| J      |              2516.94 |
| L      |              839.218 |
|--------+----------------------|
| Total  |            19528.845 |
|--------+----------------------|
#+TBLFM: @12$2=vsum(@2$2..@11$2)

* Systematic Uncertainties
A systematic error in an experiment is an error introduced by the
method of measurement. This is in contrast to a statistical error
which arises due to the finite number of events in the analysis. In
theory, statistical errors can be made arbitrarily small by collecting
arbitrarily large amounts of data. Systematic errors, which are
intrinsic to the measurement, cannot be made smaller by collecting
more data. If a systematic error is found to be too large, more
sophisticated methods must be used to reduce the error. In this
analysis, the systematic errors are assessed on the Monte Carlo
simulation, the unfolding procedure, and the background subtraction.
In each case, the source of the systematic error is assessed by
applying a change to the procedure and taking the difference from the
nominal result as the symmetric error. These errors are added in
quadrature with the statistical error to produce the final error band.
** Trigger shape
As mentioned previously, the trigger choice presents the possibility
of significantly biasing the result if care is not taken.  The
standard trigger recommendations suggest taking either an isolated
muon trigger, or the non-isolated trigger used by this analysis.  In
the former case an isolation requirement is applied in order to
increase the quality of the reconstructed muon.  An isolation
requirement ensures that there is no extraneous radiation in the
vicinity of the reconstructed muon. This is counterproductive to the
goal of this analysis.  Figure \ref{fig:trigger-shapes} shoes the
interest variables broken down by trigger choice and demonstrates the
bias of using an isolated trigger.
#+BEGIN_LaTeX
    \begin{figure}
      \centering
      \subfloat[$z$]{
        \label{fig:jet_z-trigger}
        \includegraphics[width=0.45\textwidth]{plots/trigger/jet_z.pdf}
      }\qquad
      \subfloat[$\Delta R$]{
        \label{fig:delta_r-trigger}
        \includegraphics[width=0.45\textwidth]{plots/trigger/delta_r.pdf}
      } \caption{\label{fig:trigger-shapes} Comparison of isolated an
      non-isolated trigger for the variables of interest, $z$ and
      $\Delta R$.}
  \end{figure}
#+END_LaTeX


** Monte Carlo
The Monte Carlo samples are used in the response matrix estimation, as
well as in comparing the shape to data. They contain the best
description of the detector available. There are three main effects
that can systematically change the estimate of the four vector of the
track based observables: the scale of the track (ie a shift in the
mean of the distribution), the resolution of the track and the
efficiency to reconstruct the track (ie a shift in the width of the
distribution). Muons are further complicated by the fact that they are
the estimate of two detector subsystems, the inner detector and the
muon spectrometer. Therefore there are systematic effects associated
with each of these contributions to the momentum measurement.

Previous measurements of the inclusive tracking efficiency for muons
using the tag-and-probe method allow an efficiency scale factor to be
applied to simulated data \cite{Aad:2014rra}. The uncertainty on the
energy scale of the muon is found by varying the energy up and down
depending on the p_T and $\eta$ of the muon. As mentioned above, muons
consist of a ID and MS track, leading to resolution terms from each
part of the detector. These are assessed separately and added in
quadrature with the rest of the systematic errors.

Similar to muons, the track jets also have efficiency, scale, and
resolution uncertainties. In order to assess their overall impact on
substructure variables, the jet reconstruction is run on each
variation. Previous measurements of the tracking efficiency allow
tracks to be dropped randomly according to this distribution to assess
the effect of missing a track during reconstruction \cite{Aad:2010ac}.
This is the largest source of systematic error on the Monte Carlo
samples used. Modifying the momentum scale of each track by 2% is
shown to adequately cover this uncertainty \cite{Aad:2014xaa}. The
resolution (how closely two tracks if slightly different momentum can
be resolved) is found by varying the four vector of each track
according to a gaussian with width 10% of the nominal momentum
\cite{ATLAS-CONF-2012-141}.

** Unfolding
The largest source of uncertainty in unfolding is the estimation of
the response matrix. This is assessed by estimating a new response
matrix for each variation described in the previous section on Monte
Carlo uncertainties. The resulting matrix is used to unfold the data,
and the difference from the nominal result is added in quadrature with
the remaining errors. In addition to this source of error, there are
the statistical errors which are propagated through the method as part
of the algorithm. The final source of error is on the method itself.
This is assessed by filling a pseudo-truth distribution, folding it
with the response matrix, and unfolding the result. The error is the
difference between the unfolded psuedo-truth and the pseudo-truth
distribution.
** Background Subtraction
Correct estimation of the background depends on the empirical
parameterization of the signal and background processes.  In order to
assess the effect that each component has on the overall estimate of
the background, a different model is assumed for each component.  The
background subtraction technique is applied with this variation, and
the difference from the nominal result is taken as the error for that
part of the parametric model. 

*Resolution:* The resolution of the lifetime distribution is modeled
with a double-gaussian. This allows two widths to float as well as
their relative normalization to better capture the distribution
observed in data. In order to assess the impact of this choice, a
single gaussian is used.

*Combinatoric Mass:* The combinatoric component of the mass background
is modeled as the sum of an exponential term and a first degree
polynomial. The effect of this choice is assessed by separately making
the exponential term a constant, and varying the degree of the
polynomial between one and three.

*Mismeasured $L_{xy}$ background:* There are a fraction of events
whose $L_{xy}$ values are mismeasured. This is parametrized by
symmetric exponential centered at $c\tau=0$. The choice of this
parameterization is assessed by restricting the exponential to be
one-sided for negative lifetimes.

*Crystal ball parameters:* The crystal ball function (Equation
\ref{eq:crystal-ball}) models radiative losses through asymmetric
tails in the gaussian distribution. The parameters $\alpha$ and $n$
control the strength of this effect. The $\alpha$ parameter is set to
$\alpha=1$ from its nominal value of $\alpha=10$. The $n$ parameter is
set to $n=5$ from its nominal value of $n=1$.

* Results
This analysis produces three distributions: the inclusive distribution
of signal and background (Figures \ref{fig:jet_z-splot} and
\ref{fig:delta_r-splot}), the background subtracted detector level
distribution, and the unfolded distributions (Figures
\ref{fig:jet_z-unfolded} and \ref{fig:delta_r-unfolded}). The
background subtracted distribution is compared to Pythia's prediction
which also has event reconstruction applied (Figures
\ref{fig:jet_z-sbs-p8} and \ref{fig:delta_r-sbs-p8}). The inclusive
distributions and the unfolded distributions are presented on their
own. 
#+BEGIN_LaTeX
  \begin{figure}
    \centering
    \subfloat[Signal vs Pythia 8, $z$]{
      \label{fig:jet_z-sbs-p8}
      \includegraphics[width=0.45\textwidth]{plots/jet_z_sbs_p8.pdf}
    }\qquad
    \subfloat[Signal and background vs data, $z$]{
      \label{fig:jet_z-splot}
      \includegraphics[width=0.45\textwidth]{plots/jet_z_splot.pdf}
    }\\
     \subfloat[Signal vs Pythia 8, $\Delta R$]{
      \label{fig:delta_r-sbs-p8}
      \includegraphics[width=0.45\textwidth]{plots/delta_r_sbs_p8.pdf}
    } \qquad
    \subfloat[Signal and background vs data, $\Delta R$]{
      \label{fig:delta_r-splot}
      \includegraphics[width=0.45\textwidth]{plots/delta_r_splot.pdf}
    }\caption{\label{fig:sbs-p8} (left panel) Pythia's prediction
    compared to subtracted data for $z$ and $\Delta R$ observables. The
    stack shows each component of prompt $J/\psi$ production in Pythia,
    the grey error band is the quadrature sum of all systematic error
    sources across all MC samples. The dominant components are
    $^3P_J^{(1)}$ and $^3S_1^{(8)}$ due to the relative size of their
    cross sections based on the default parameters. (right panel) The
    estimated signal and background components estimated from sPlot. The
    signal is added to the background to show closure with the observed
    data. Error bars are the statistical errors on the method.}
  \end{figure}
#+END_LaTeX
#+BEGIN_LaTeX
  \begin{figure}
    \centering
    \subfloat[$z$]{
      \label{fig:jet_z-unfolded}
      \includegraphics[width=0.45\textwidth]{plots/jet_z_unfolded.pdf}
    }\qquad
    \subfloat[$\Delta R$]{
      \label{fig:delta_r-unfolded}
      \includegraphics[width=0.45\textwidth]{plots/delta_r_unfolded.pdf}
    } \caption{\label{fig:unfolded} Unfolded signal distributions for
    $z$ and $\Delta R$ observables. The shaded error band is the
    statistical (dark grey) and fit systematic (light grey). The error
    on the data is the quadrature sum of all error sources. }
\end{figure}
#+END_LaTeX
#+LaTeX: \chapter{Conclusion}
#+LaTeX: \label{chap:conclusion}
* Discussion
This analysis has identified two variables for describing the
production of $J/\psi$ particles in hadronic collisions that have
previously been poorly explored. The $\Delta R$ distribution in
\ref{fig:delta_r-sbs-p8} shows that the data peaks in a slightly
different place and has longer tail than the combination of singlet
and octet components provided by Pythia. The momentum fraction $z$
(Figure \ref{fig:jet_z-sbs-p8}) has the most significant disagreement
between the Pythia prediction and the observed data. The data seems to
indicate that more momentum is carried by the jet than the $J/\psi$
candidate.

The momentum fraction $z$ directly probes the parton shower splitting
leading up to the production of the $J/\psi$. Pythia models this
process by allowing the $c\bar{c}$ state to radiate gluons until the
state falls below a threshold at which point it emits as soft gluon
and produces a $J/\psi$. The fact that the splitting function used is
$q \rightarrow qg$ leads to a $z$ distribution that is sharply peaked
at $z\simeq1$. If instead, the $J/\psi$ is produced during the
fragmentation of an energetic gluon, the proper splitting function is
$g \rightarrow gg$ until the gluon reaches an energy favorable for
$J/\psi$ production. This would influence the $z$ distribution causing
it to peak at lower values of $z$ as observed in the data. A recent
measurement at the LHCb \cite{Aaij:2017fak} of the momentum fraction,
$z$ at $|\eta| > 2.5$ and $\sqrt{s}=13$ TeV shows a similar
discrepancy between Pythia's description and the observed data. A
recent analysis of the data \cite{Bain:2017wvk} supports the gluon
fragmentation interpretation of the data. If this is borne out by
further analysis of the unfolded data presented in this work, a
solution to the polarization puzzle may be found by examining the
surrounding radiation in which $J/\psi$ production is embedded.

The shape of the data, and the differences between how the $J/\psi$ is
produced in the Fragmenting Jet Function (FJF) framework compared to
Pythia suggest that modifying Pythia's treatment of the octet state
shower may reduce disagreement between the data and the simulation.
Furthermore, Pythia is the only general purpose Monte Carlo generator
available that produces $J/\psi$ using the NRQCD description of
$J/\psi$ production. This work indicates the need for more robust
Monte Carlo simulations which better describe $J/\psi$ production in
hadronic collisions. Work has been done to implement the partonic
cross sections for NRQCD quarkonium states in Sherpa. If this work is
published, Sherpa may provide a valuable cross check to Pythia's
prediction. In addition, Sherpa is well placed to modify its treatment
of the parton shower of the quarkonium state from the outset.

This work provides new observables that may constrain the
predictions from NRQCD in interesting ways. It may be possible to use
the $z$ distribution to extract new LDMEs and subsequently compare to
the $p_T$ spectrum (or vice versa). In the original incarnation of
this work, other substructure variables were shown to discriminate
between the singlet and octet processes as simulated by Pythia. It may
be possible to extend this work to include those and other
substructure variables in a way that further illuminates the exact
production mechanism. In addition, the $J/\psi$ system is used
extensively in heavy ion collisions as a probe of the quark-gluon
plasma produced in those interactions. Having a new understanding of
how the quarkonium bound state is produced may require reinterpreting
many results that extend beyond $J/\psi$ production in hadron
collisions.

In closing, this work demonstrates the need to study the hadronic
environment that a quarkonium state is embedded in. It is the first
measurement of ultra-high $p_T$ J/\psi particles and has demonstrated
techniques for robust background subtraction and the removal of
non-linear detector effects. The resulting data will be immediately
useful to theorists in further understanding how $J/\psi$ particles
are produced in hadron collisions. Finally, this work may provide the
first hints at a way to reinterpret $J/\psi$ production so that the
spin-alignment problem, or polarization puzzle, can be solved
definitively.

#+BEGIN_LaTeX
\cleardoublepage
\normalbaselines %Fixes spacing of bibliography
\addcontentsline{toc}{chapter}{Bibliography} %adds Bibliography to your table of contents
\printbibliography
#+END_LaTeX

#+INCLUDE: biography.org
